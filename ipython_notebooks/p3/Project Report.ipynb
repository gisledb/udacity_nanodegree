{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing classes from display and pretty print modules\n",
    "from pprint import pprint\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "#importing other necessary modules and packages\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pymongo import MongoClient\n",
    "from operator import itemgetter\n",
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#For convenience imports are also included in individual cells where relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from pprint import pprint\n",
    "\n",
    "#Setting up MongoDB connection\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.osm\n",
    "#Creating db.bergen as a variable for the sake of brevity\n",
    "bergen = db.bergen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The aim of this document is to give a summary of the wrangling and analysis process performed in the OSM project, and to highlight interesting findings from that process. For more details about the data wrangling and data analysis processes, see <a href=\"http://htmlpreview.github.io/?https://github.com/gisledb/udacity_nanodegree/blob/master/ipython_notebooks/p3/osm_analysis.html\">osm_analysis.html</a> and <a href=\"http://htmlpreview.github.io/?https://github.com/gisledb/udacity_nanodegree/blob/master/ipython_notebooks/p3/osm_data_wrangling.html\">osm_data_wrangling.html</a>.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before starting on the project, my overall goal was to analyze the OpenStreetMaps (OSM) data for my hometown Bergen, and hopefully discover some interesting findings during this process. As you will show later in the report, the main discoveries are related to data errors and structure of the user community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-import Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I started by going to OpenStreetMaps.com and finding the correct entity for the city of Bergen area I wanted to analyze. I settled on using the boundary type entity with boundary variable set to \"administrative\". Next I went to https://mapzen.com/data/metro-extracts/ to generate and download the necessary data file for Bergen.  \n",
    "\n",
    "Once I had the bergen.osm data file it was time for the pre-import wrangling process (full details <a href=\"http://htmlpreview.github.io/?https://github.com/gisledb/udacity_nanodegree/blob/master/ipython_notebooks/p3/osm_data_wrangling.html\">here</a>). I started by doing some experiments on a generated sample file, and settled on 2 focus areas for ensuring data quality in the pre-import cleaning phase:  \n",
    "1) ensuring good quality of postcodes, and correcting erroneous ones.  \n",
    "2) ensuring good quality of street names within Bergen.\n",
    "\n",
    "During the analysis, I discovered a few addresses with incorrect postcode format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 21641553\n",
      "name: Kiwi minipris\n",
      "shop: supermarket\n",
      "amenity: post_office\n",
      "nat_name: Kiwi minipris Frekhaug\n",
      "addr:city: Frekhaug\n",
      "wheelchair: yes\n",
      "addr:street: Havneveien\n",
      "addr:country: NO\n",
      "addr:postcode: NO-5918\n",
      "addr:housenumber: 36\n",
      "----\n",
      "id: 2698046129\n",
      "name: Data Respons AS (Bergen office)\n",
      "phone: +47 55 38 30 40\n",
      "source: http://datarespons.com/Company-test/Offices-and-people/Norway/Bergen/\n",
      "website: http://datarespons.com\n",
      "addr:city: Bergen\n",
      "addr:street: Edvard Griegs vei\n",
      "addr:postcode: NO-5059\n",
      "addr:housenumber: 3A\n",
      "----\n",
      "id: 2698046139\n",
      "name: Itslearning HQ\n",
      "phone: +47 55 23 60 70\n",
      "office: yes\n",
      "source: http://www.itslearning.eu/itslearning-hq-bergen-norway\n",
      "website: http://www.itslearning.eu\n",
      "addr:city: Bergen\n",
      "addr:street: Edvard Griegs vei\n",
      "addr:postcode: NO-5059\n",
      "addr:housenumber: 3A\n",
      "----\n",
      "id: 3645588506\n",
      "name: Circle K\n",
      "brand: Circle K\n",
      "amenity: fuel\n",
      "operator: Circle K Norge AS\n",
      "addr:city: Bergen\n",
      "addr:street: Helleveien\n",
      "addr:postcode: NO-5035\n",
      "addr:housenumber: 34\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for _, element in ET.iterparse('data/bergen.osm'):\n",
    "    if element.tag == 'node':\n",
    "        tags = element.findall('tag')\n",
    "        for el in tags:\n",
    "            attrib_dict = el.attrib\n",
    "            if attrib_dict['k'] == 'addr:postcode':\n",
    "                if attrib_dict['v'][0:2] == 'NO':\n",
    "                    print(\"id:\",element.attrib['id'])\n",
    "                    for addr in tags:\n",
    "                        print(\"{0}: {1}\".format( addr.attrib['k'],addr.attrib['v'] ) )\n",
    "                    print('----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these four addresses have incorrect postcode format: They include the country abbreviation \"NO\", while we are only interested in the four digit postcode itself. I cleaned these erroneous records before importing the osm json file to MongoDB. During my analysis, I ensured that the postcodes were in fact corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21641553 {'postcode': '5918', 'housenumber': '36', 'street': 'Havneveien', 'country': 'NO', 'city': 'Frekhaug'}\n",
      "----\n",
      "2698046129 {'postcode': '5059', 'housenumber': '3A', 'street': 'Edvard Griegs vei', 'city': 'Bergen'}\n",
      "----\n",
      "2698046139 {'postcode': '5059', 'housenumber': '3A', 'street': 'Edvard Griegs vei', 'city': 'Bergen'}\n",
      "----\n",
      "3645588506 {'postcode': '5035', 'housenumber': '34', 'street': 'Helleveien', 'city': 'Bergen'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#After corrections, result from mongodb\n",
    "\n",
    "def print_address(_id):\n",
    "    if type(_id) == (str or int):\n",
    "        _id = [_id]\n",
    "    for item in _id:\n",
    "        item = str(item)\n",
    "        search = bergen.find_one( {'id': item} )\n",
    "        print(search['id'], search['address'] )\n",
    "        print('----')\n",
    "\n",
    "print_address([21641553, 2698046129,2698046139,3645588506])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/wikipedia_bergen_streets.jpg\" align=\"right\" width=\"290\">\n",
    "\n",
    "Next I had to come up with a good way for measuring street name quality. Since words and names in Norwegian often are concatenated I could not reuse the regex based strategy from the lecture videos. I decided to instead put the most common street name endings into a list which I compared all the street names in the data file too. I quickly discovered that there are way too many street names in Bergen which do not follow a common naming structure, so I realized I needed to come up with an additional strategy for the quality audit.\n",
    "\n",
    "I decided on a strategy of comparing the street names in the osm data file with street names from more or less official sources. I first scraped a Norwegian wikipedia article which listed all the street names in Bergen, with original data source being the Norwegian Mapping Authority. Since the list was quite dated (from 2005), I decided to look for alternative sources as well. I discovered that the Norwegian Public Roads Administration (NPRA) has a public API containing all the official Norwegian streetnames, which I used to generate a second list of Bergen street names.\n",
    "\n",
    "I then combined the street names from the two sources and removed any duplicates, ending up with a list of 2093 Bergen street names. At that point I felt I had a good foundation to continue with the quality audit.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I first compared the osm data set to my list of Bergen street names, the search returned an unexpected high number of non-matched osm street names. While spot checking the street names, I noticed that several of them were located outside of the city of Bergen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '2012-07-22T21:23:45Z', 'changeset': '12440624', 'lat': '60.5176144', 'id': '21641553', 'lon': '5.2397614', 'version': '6', 'uid': '1694', 'user': 'M E Menk'}\n",
      "{'k': 'addr:city', 'v': 'Frekhaug'}\n",
      "{'k': 'addr:street', 'v': 'Havneveien'}\n",
      "{'k': 'addr:country', 'v': 'NO'}\n",
      "{'k': 'addr:postcode', 'v': 'NO-5918'}\n",
      "{'k': 'addr:housenumber', 'v': '36'}\n"
     ]
    }
   ],
   "source": [
    "for _, element in ET.iterparse('data/bergen.osm'):\n",
    "    if element.tag == 'node':\n",
    "        if element.attrib['id'] == '21641553':\n",
    "            print(element.attrib)\n",
    "            for el in element:\n",
    "                if el.attrib['k'][0:4] == 'addr':\n",
    "                    print(el.attrib)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dig deeper into this, I downloaded an offical dataset from the Norwegian postal service containing all the postcodes in Norway, postcode name and municipality. When I compared the postal service postcodes to all the postcodes in the osm dataset, I discovered that some of the osm documents are located in cities outside of the municipality of Bergen.\n",
    "\n",
    "Since I mainly focus on Bergen in this project, I decided to limit my address corrections to adresses within Bergen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-c23994035e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'way'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_postcode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'elem' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "postcodes_per_municipality = pd.read_csv('data/Postnummerregister_ansi.tsv', encoding='utf-8',delimiter='\\t',header=0, names=[\n",
    "        'postal_code','postal_place','muni_number','muni_name','category'],\n",
    "            dtype = {'postal_code': str, 'municipality_number': str})\n",
    "\n",
    "postcodes_per_municipality.head(5)\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.attrib.setdefault('k',None) == \"addr:postcode\")\n",
    "\n",
    "for _, element in ET.iterparse('data/bergen.osm'):\n",
    "    if element.tag in ['way']:\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            print(elem.attrib.setdefault('k',None))\n",
    "            if is_postcode(tag):\n",
    "                print(tag.attrib['v'])\n",
    "        break\n",
    "#                 if tag.attrib['v'] in postcodes_per_municipality['postal_code']:\n",
    "#                     print(tag.attrib['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the postal service postcode dataset to improve my postcode audit, and except for the already mentioned postcode errors, all the postcodes in the osm dataset matched postcodes in the official postcode dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deciding on the criteria for the street name audit, I compared the osm street names to the street names from the official sources, and the common street name suffixes. This resulted in 15 osm street names within Bergen not found in the official street name dataset. I manually reviewed these 15 street names, and excluded 6 of these from further corrections. One of these are actually a correct street name, verified through online research, while 5 of these cannot easily be corrected (post box address, name of shopping center, unknown street names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 9 remaining street names:\n",
      "['Hesthaugvn.',\n",
      " 'Christies Gate',\n",
      " 'Steinsvikvegen 430',\n",
      " 'Smøråshøgda 9',\n",
      " 'Minde alle',\n",
      " 'Thormøhlens Gate',\n",
      " 'Vilhelm Bjerknesvei 4-10',\n",
      " 'Tokanten',\n",
      " 'Laguneveien 1']\n",
      "Corrected using the following critera:\n",
      "{' Gate': ' gate',\n",
      " ' alle': ' allé',\n",
      " 'Tokanten': 'Nesttunveien',\n",
      " 'vei 4-10': 'vei',\n",
      " 'vn.': 'vegen'}\n"
     ]
    }
   ],
   "source": [
    "mapping = mapping = { \" Gate\": \" gate\", \" alle\": \" allé\", \"vn.\": \"vegen\",\n",
    "           \"Tokanten\": \"Nesttunveien\", \"vei 4-10\": \"vei\"\n",
    "            }\n",
    "\n",
    "print(\"The 9 remaining street names:\")\n",
    "\n",
    "pprint(['Hesthaugvn.',\n",
    " 'Christies Gate',\n",
    " 'Steinsvikvegen 430',\n",
    " 'Smøråshøgda 9',\n",
    " 'Minde alle',\n",
    " 'Thormøhlens Gate',\n",
    " 'Vilhelm Bjerknesvei 4-10',\n",
    " 'Tokanten',\n",
    " 'Laguneveien 1'])\n",
    "\n",
    "print(\"Corrected using the following critera:\")\n",
    "pprint(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the criteria for the address audit were finalized and implemented, I created and ran a function to generate a json file to import to mongodb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is a summary of the analysis in osm_analysis.ipynb/osm_analysis.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting a general feel of the address data in the dataset, I went on to look for misspelled streetnames. To include near-matches I used a Python library named Fuzzywuzzy. After experimenting a little I settled on a fairly high fuzzy score of 90 as a criteria for further analysis. \n",
    "\n",
    "In the end I ended up correcting [] address documents containing 15 different misspelled street names, and I exported 4 additional street names to research_street_spellings.csv which require more research than the scope of this project allows. []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I looked for duplicate addresses in the dataset. I found quite a few duplicate addresses, but due to vague OSM policies it is unclear whether to consider this as incorrect data. In the cases of multiple businesses at the same address having the same address, the OSM wiki states: \"However, there is still some debate on that point (see for example Address information in POI *and* building? on help.openstreetmap.org). Also, the community in some countries has established their own rules.\"\n",
    "\n",
    "To address the duplicate issue in detail, I suggest following up by looking at the individual duplicate addresses. You could for example start by looking at the three streets with the most individual duplicate addresses to see if there are any useful patterns to be found. []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I had a look at the distribution of user edits in the Bergen OSM data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
