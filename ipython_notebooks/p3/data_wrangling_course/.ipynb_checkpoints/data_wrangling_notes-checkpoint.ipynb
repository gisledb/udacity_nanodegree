{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'BPI Certification': 'Gold',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': 'Platinum',\n",
       "  'Released': '22 March 1963',\n",
       "  'Title': 'Please Please Me',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': 'Gold',\n",
       "  'Released': '22 November 1963',\n",
       "  'Title': 'With the Beatles',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(CAN)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '25 November 1963',\n",
       "  'Title': 'Beatlemania! With the Beatles',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Vee-Jay(US)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '10 January 1964',\n",
       "  'Title': 'Introducing... The Beatles',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '2'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': '5xPlatinum',\n",
       "  'Released': '20 January 1964',\n",
       "  'Title': 'Meet the Beatles!',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(CAN)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '3 February 1964',\n",
       "  'Title': 'Twist and Shout',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': '2xPlatinum',\n",
       "  'Released': '10 April 1964',\n",
       "  'Title': \"The Beatles' Second Album\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(CAN)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '11 May 1964',\n",
       "  'Title': \"The Beatles' Long Tall Sally\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'United Artists(US)[C]',\n",
       "  'RIAA Certification': '4xPlatinum',\n",
       "  'Released': '26 June 1964',\n",
       "  'Title': \"A Hard Day's Night\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Gold',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '10 July 1964',\n",
       "  'Title': '',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lesson 1 - Quiz: Parsing CSV files\n",
    "#My solution inspired (not copied, made some tweaks) by answer in stack overflow\n",
    "\n",
    "\n",
    "# Your task is to read the input DATAFILE line by line, and for the first 10 lines (not including the header)\n",
    "# split each line on \",\" and then for each line, create a dictionary\n",
    "# where the key is the header title of the field, and the value is the value of that field in the row.\n",
    "# The function parse_file should return a list of dictionaries,\n",
    "# each data line in the file being a single list entry.\n",
    "# Field names and values should not contain extra whitespace, like spaces or newline characters.\n",
    "# You can use the Python string method strip() to remove the extra whitespace.\n",
    "# You have to parse only the first 10 data lines in this exercise,\n",
    "# so the returned list should have 10 entries!\n",
    "import os\n",
    "\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"beatles-diskography.csv\"\n",
    "\n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    \n",
    "    with open(datafile, 'r') as f:\n",
    "\n",
    "        firstline = True\n",
    "        count = 0\n",
    "\n",
    "        for line in f:\n",
    "            count += 1\n",
    "            if firstline:\n",
    "                mykeys = list(line.split(','))\n",
    "                firstline = False\n",
    "            else:\n",
    "                values = list(line.split(','))\n",
    "                data.append({mykeys[n].strip():values[n].strip() for n in range(0,len(mykeys))})\n",
    "\n",
    "            if count > 10:\n",
    "                break\n",
    "\n",
    "    return data\n",
    "\n",
    "parse_file('beatles-diskography.csv')\n",
    "\n",
    "# def test():\n",
    "#     # a simple test of your implemetation\n",
    "#     datafile = os.path.join(DATADIR, DATAFILE)\n",
    "#     d = parse_file(datafile)\n",
    "#     firstline = {'Title': 'Please Please Me', 'UK Chart Position': '1', 'Label': 'Parlophone(UK)', 'Released': '22 March 1963', 'US Chart Position': '-', 'RIAA Certification': 'Platinum', 'BPI Certification': 'Gold'}\n",
    "#     tenthline = {'Title': '', 'UK Chart Position': '1', 'Label': 'Parlophone(UK)', 'Released': '10 July 1964', 'US Chart Position': '-', 'RIAA Certification': '', 'BPI Certification': 'Gold'}\n",
    "\n",
    "#     print(d[0])\n",
    "#     print(firstline)\n",
    "#     assert d[0] == firstline\n",
    "#     assert d[9] == tenthline\n",
    "\n",
    "    \n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "{'Title,Released,Label,UK': 'Please', 'Position,BPI': '1963,Parlophone(UK),1,—,Gold,Platinum', 'Chart': 'March', 'Position,US': 'Me,22'}\n",
      "['Please', 'Please', 'Me,22', 'March', '1963,Parlophone(UK),1,—,Gold,Platinum']\n"
     ]
    }
   ],
   "source": [
    "#NO DID NOT WORK\n",
    "\n",
    "# DATADIR = \"\"\n",
    "# DATAFILE = \"beatles-diskography.csv\"\n",
    "\n",
    "# data = []\n",
    "# count = 0\n",
    "# tmp_list = []\n",
    "# with open(DATAFILE, \"r\") as f:\n",
    "#     for line in f:\n",
    "#         #print(line)\n",
    "#         tmp_list.append(list(line.split()))\n",
    "        \n",
    "#         count += 1\n",
    "\n",
    "#         if count > 10:\n",
    "#             break\n",
    "        \n",
    "# col_index = tmp_list[0]\n",
    "\n",
    "# col_index\n",
    "\n",
    "# for sublist in tmp_list[1:]:\n",
    "#     tmp_dict = dict()\n",
    "#     #needed in case of duplicate values in sublist\n",
    "#     tmp_ix = list()\n",
    "#     for val in sublist:\n",
    "#         sublist_pos = sublist.index(val)\n",
    "#         if val in tmp_ix:\n",
    "#             val_ixp = sublist[sublist_pos+1:].index(val)\n",
    "#         else:\n",
    "#             val_ixp = sublist_pos\n",
    "#         tmp_ix.append(val)\n",
    "#         tmp_dict[col_index[val_ixp]] = val\n",
    "        \n",
    "#         print(val_ixp)\n",
    "    \n",
    "#     print(tmp_dict)\n",
    "#     break\n",
    "\n",
    "# print(tmp_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor had slightly different solution, see P3: DataWrangling coruse, video Quiz: Parsing CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'BPI Certification': 'Gold',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': 'Platinum',\n",
       "  'Released': '22 March 1963',\n",
       "  'Title': 'Please Please Me',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': 'Gold',\n",
       "  'Released': '22 November 1963',\n",
       "  'Title': 'With the Beatles',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(CAN)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '25 November 1963',\n",
       "  'Title': 'Beatlemania! With the Beatles',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Vee-Jay(US)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '10 January 1964',\n",
       "  'Title': 'Introducing... The Beatles',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '2'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': '5xPlatinum',\n",
       "  'Released': '20 January 1964',\n",
       "  'Title': 'Meet the Beatles!',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(CAN)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '3 February 1964',\n",
       "  'Title': 'Twist and Shout',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': '2xPlatinum',\n",
       "  'Released': '10 April 1964',\n",
       "  'Title': \"The Beatles' Second Album\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(CAN)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '11 May 1964',\n",
       "  'Title': \"The Beatles' Long Tall Sally\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'United Artists(US)[C]',\n",
       "  'RIAA Certification': '4xPlatinum',\n",
       "  'Released': '26 June 1964',\n",
       "  'Title': \"A Hard Day's Night\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Gold',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '10 July 1964',\n",
       "  'Title': '',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': 'Platinum',\n",
       "  'Released': '20 July 1964',\n",
       "  'Title': 'Something New',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '2'},\n",
       " {'BPI Certification': 'Gold',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': 'Platinum',\n",
       "  'Released': '4 December 1964',\n",
       "  'Title': 'Beatles for Sale',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': '3xPlatinum',\n",
       "  'Released': '15 December 1964',\n",
       "  'Title': \"Beatles '65\",\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Parlophone(NZ), Capitol(US)',\n",
       "  'RIAA Certification': 'Platinum',\n",
       "  'Released': '14 June 1965',\n",
       "  'Title': 'Beatles VI',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '6 August 1965',\n",
       "  'Title': 'Help!',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)[C]',\n",
       "  'RIAA Certification': '3xPlatinum',\n",
       "  'Released': '13 August 1965',\n",
       "  'Title': '',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '3 December 1965',\n",
       "  'Title': 'Rubber Soul',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)[C]',\n",
       "  'RIAA Certification': '6xPlatinum',\n",
       "  'Released': '6 December 1965',\n",
       "  'Title': '',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)',\n",
       "  'RIAA Certification': '2xPlatinum',\n",
       "  'Released': '15 June 1966',\n",
       "  'Title': 'Yesterday and Today',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Parlophone(UK)',\n",
       "  'RIAA Certification': '',\n",
       "  'Released': '5 August 1966',\n",
       "  'Title': 'Revolver',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '—'},\n",
       " {'BPI Certification': '',\n",
       "  'Label': 'Capitol(US)[C]',\n",
       "  'RIAA Certification': '5xPlatinum',\n",
       "  'Released': '8 August 1966',\n",
       "  'Title': '',\n",
       "  'UK Chart Position': '—',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': '3xPlatinum',\n",
       "  'Label': 'Parlophone(UK), Capitol(US)',\n",
       "  'RIAA Certification': '11xPlatinum',\n",
       "  'Released': '1 June 1967',\n",
       "  'Title': \"Sgt. Pepper's Lonely Hearts Club Band\",\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Parlophone(UK), Capitol(US)',\n",
       "  'RIAA Certification': '6xPlatinum',\n",
       "  'Released': '27 November 1967',\n",
       "  'Title': 'Magical Mystery Tour',\n",
       "  'UK Chart Position': '31[D]',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Platinum',\n",
       "  'Label': 'Apple(UK), Capitol(US)',\n",
       "  'RIAA Certification': '19xPlatinum',\n",
       "  'Released': '22 November 1968',\n",
       "  'Title': 'The Beatles',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Silver',\n",
       "  'Label': 'Apple(UK), Capitol(US)',\n",
       "  'RIAA Certification': 'Platinum',\n",
       "  'Released': '13 January 1969',\n",
       "  'Title': 'Yellow Submarine',\n",
       "  'UK Chart Position': '3',\n",
       "  'US Chart Position': '2'},\n",
       " {'BPI Certification': '2xPlatinum',\n",
       "  'Label': 'Apple(UK), Capitol(US)',\n",
       "  'RIAA Certification': '12xPlatinum',\n",
       "  'Released': '26 September 1969',\n",
       "  'Title': 'Abbey Road',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '1'},\n",
       " {'BPI Certification': 'Gold',\n",
       "  'Label': 'Apple(UK),United Artists(US)',\n",
       "  'RIAA Certification': '4xPlatinum',\n",
       "  'Released': '8 May 1970',\n",
       "  'Title': 'Let It Be',\n",
       "  'UK Chart Position': '1',\n",
       "  'US Chart Position': '1'}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using CSV module\n",
    "import os\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"beatles-diskography.csv\"\n",
    "\n",
    "data = []\n",
    "\n",
    "def parse_csv(datafile):\n",
    "    data = []\n",
    "    n = 0\n",
    "    with open(datafile, 'r') as sd:\n",
    "        r = csv.DictReader(sd)\n",
    "        for line in r:\n",
    "            data.append(line)\n",
    "        return data\n",
    "    \n",
    "parse_csv(DATAFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List Comprehension\n",
      "data[3][2]:\n",
      "1036.0886969999988\n",
      "\n",
      "Cells in a nested loop:\n",
      "41277.083333333336\n",
      "9238.737309999968\n",
      "1438.2052799999994\n",
      "1565.4428559999976\n",
      "916.7083480000003\n",
      "14010.903488000036\n",
      "3027.9833399999993\n",
      "6165.211119000006\n",
      "1157.7416630000007\n",
      "37520.93340400001\n",
      "\n",
      "ROWS, COLUMNS, and CELLS:\n",
      "Number of rows in the sheet:\n",
      "7296\n",
      "Type of data in cell (row 3, col 2):\n",
      "2\n",
      "Value in cell (row 3, col 2):\n",
      "1036.0886969999988\n",
      "Get a slice of values in column 3, from rows 1-3:\n",
      "[1411.7505669999982, 1403.4722870000019, 1395.053150000001]\n",
      "\n",
      "DATES:\n",
      "Type of data in cell (row 1, col 0):\n",
      "3\n",
      "Time in Excel format:\n",
      "41275.041666666664\n",
      "Convert time to a Python datetime tuple, from the Excel float:\n",
      "(2013, 1, 1, 1, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "#XLRD for xls and xlsx files\n",
    "#Code from video\n",
    "\n",
    "import xlrd\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    data = [[sheet.cell_value(r, col) \n",
    "                for col in range(sheet.ncols)] \n",
    "                    for r in range(sheet.nrows)]\n",
    "\n",
    "    print(\"\\nList Comprehension\")\n",
    "    print(\"data[3][2]:\",)\n",
    "    print(data[3][2])\n",
    "\n",
    "    print(\"\\nCells in a nested loop:\"    )\n",
    "    for row in range(sheet.nrows):\n",
    "        for col in range(sheet.ncols):\n",
    "            if row == 50:\n",
    "                print(sheet.cell_value(row, col),)\n",
    "\n",
    "\n",
    "    ### other useful methods:\n",
    "    print(\"\\nROWS, COLUMNS, and CELLS:\")\n",
    "    print(\"Number of rows in the sheet:\", )\n",
    "    print(sheet.nrows)\n",
    "    print(\"Type of data in cell (row 3, col 2):\", )\n",
    "    print(sheet.cell_type(3, 2))\n",
    "    print(\"Value in cell (row 3, col 2):\", )\n",
    "    print(sheet.cell_value(3, 2))\n",
    "    print(\"Get a slice of values in column 3, from rows 1-3:\")\n",
    "    print(sheet.col_values(3, start_rowx=1, end_rowx=4))\n",
    "\n",
    "    print(\"\\nDATES:\")\n",
    "    print(\"Type of data in cell (row 1, col 0):\", )\n",
    "    print(sheet.cell_type(1, 0))\n",
    "    exceltime = sheet.cell_value(1, 0)\n",
    "    print(\"Time in Excel format:\",)\n",
    "    print(exceltime)\n",
    "    print(\"Convert time to a Python datetime tuple, from the Excel float:\",)\n",
    "    print(xlrd.xldate_as_tuple(exceltime, 0))\n",
    "\n",
    "    return data\n",
    "\n",
    "data = parse_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz: Reading Excel Files\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is as follows:\n",
    "- read the provided Excel file\n",
    "- find and return the min, max and average values for the COAST region\n",
    "- find and return the time value for the min and max entries\n",
    "- the time values should be returned as Python tuples\n",
    "\n",
    "Please see the test function for the expected return format\n",
    "\"\"\"\n",
    "\n",
    "import xlrd\n",
    "from zipfile import ZipFile\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "#2013_ERCOT_Hourly_Load_Data.zip\n",
    "#2013_ERCOT_Hourly_Load_Data.xls\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    ### example on how you can get the data\n",
    "    #sheet_data = [[sheet.cell_value(r, col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "\n",
    "    ### other useful methods:\n",
    "#     print(\"\\nROWS, COLUMNS, and CELLS:\")\n",
    "#     print(\"Number of rows in the sheet:\", )\n",
    "#     print(sheet.nrows)\n",
    "#     print(\"Type of data in cell (row 3, col 2):\", )\n",
    "#     print(sheet.cell_type(3, 2))\n",
    "#     print(\"Value in cell (row 3, col 2):\", )\n",
    "#     print(sheet.cell_value(3, 2))\n",
    "#     print(\"Get a slice of values in column 3, from rows 1-3:\")\n",
    "#     print(sheet.col_values(3, start_rowx=1, end_rowx=4))\n",
    "\n",
    "#     print(\"\\nDATES:\")\n",
    "#     print(\"Type of data in cell (row 1, col 0):\", )\n",
    "#     print(sheet.cell_type(1, 0))\n",
    "#     exceltime = sheet.cell_value(1, 0)\n",
    "#     print(\"Time in Excel format:\",)\n",
    "#     print(exceltime)\n",
    "#     print(\"Convert time to a Python datetime tuple, from the Excel float:\",)\n",
    "#     print(xlrd.xldate_as_tuple(exceltime, 0))\n",
    "\n",
    "    maxvalue = max(sheet.col_values(1, start_rowx=1, end_rowx=sheet.nrows))\n",
    "    minvalue = min(sheet.col_values(1, start_rowx=1, end_rowx=sheet.nrows))\n",
    "        \n",
    "    for time,value in zip(sheet.col_values(0, start_rowx=1, end_rowx=sheet.nrows),\n",
    "    sheet.col_values(1, start_rowx=1, end_rowx=sheet.nrows)):\n",
    "\n",
    "        if value == maxvalue:\n",
    "            maxtime = time\n",
    "        if value == minvalue:\n",
    "            mintime = time\n",
    "        \n",
    "    data = {\n",
    "            'maxtime': xlrd.xldate_as_tuple(maxtime,0),\n",
    "            'maxvalue': maxvalue,\n",
    "            'mintime': xlrd.xldate_as_tuple(mintime,0),\n",
    "            'minvalue': minvalue,\n",
    "            'avgcoast': sum(sheet.col_values(1, start_rowx=1, end_rowx=sheet.nrows))/(sheet.nrows-1)\n",
    "    }\n",
    "                \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "\n",
    "    assert data['maxtime'] == (2013, 8, 13, 17, 0, 0)\n",
    "    assert round(data['maxvalue'], 10) == round(18779.02551, 10)\n",
    "\n",
    "\n",
    "test()\n",
    "\n",
    "\n",
    "#Instead of the loop, the solution video uses the xlrd.index() function:\n",
    "#maxpos = sheet.col_values(1, start_rowx=1, end_rowx=None).index(maxval) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructor's solution is a little different, it doesn't use for loop (uses xlrd.index() instead) among other things. See video P3> Data Wrangling course - Quiz>: Reading Excel Files for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count of Bands named \"first aid kit\"\n",
    "begin_area name for queen\n",
    "spanish alias for beatles\n",
    "nirvana disambiguation\n",
    "when was one direction formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bands named First Aid Kid: 2\n",
      "Begin area for Queen: London\n",
      "Spanish alias of Beatles: Los Beatles\n",
      "Nirvana disambiguation 90s US grunge band\n",
      "One direction est.: 2010-07\n"
     ]
    }
   ],
   "source": [
    "#Quiz: JSON Playground\n",
    "# To experiment with this code freely you will have to run this code locally.\n",
    "# Take a look at the main() function for an example of how to use the code.\n",
    "# We have provided example json output in the other code editor tabs for you to\n",
    "# look at, but you will not be able to run any queries through our UI.\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "BASE_URL = \"http://musicbrainz.org/ws/2/\"\n",
    "ARTIST_URL = BASE_URL + \"artist/\"\n",
    "\n",
    "# query parameters are given to the requests.get function as a dictionary; this\n",
    "# variable contains some starter parameters.\n",
    "query_type = {  \"simple\": {},\n",
    "                \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "                \"aliases\": {\"inc\": \"aliases\"},\n",
    "                \"releases\": {\"inc\": \"releases\"}}\n",
    "\n",
    "\n",
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    # This is the main function for making queries to the musicbrainz API.\n",
    "    # A json document should be returned by the query.\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def query_by_name(url, params, name):\n",
    "    # This adds an artist name to the query parameters before making\n",
    "    # an API call to the function above.\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)\n",
    "\n",
    "def query_by_id(url, params, arid):\n",
    "    # This adds an artist name to the query parameters before making\n",
    "    # an API call to the function above.\n",
    "    params[\"query\"] = \"arid:\" + arid\n",
    "    return query_site(url, params)\n",
    "\n",
    "def pretty_print(data, indent=4):\n",
    "    # After we get our output, we can format it to be more readable\n",
    "    # by using this function.\n",
    "    if type(data) == dict:\n",
    "        print(json.dumps(data, indent=indent, sort_keys=True))\n",
    "    else:\n",
    "        print(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    Modify the function calls and indexing below to answer the questions on\n",
    "    the next quiz. HINT: Note how the output we get from the site is a\n",
    "    multi-level JSON document, so try making print(statements to step through\n",
    "    the structure one level at a time or copy the output to a separate output\n",
    "    file.\n",
    "    '''\n",
    "#     results = query_by_id(ARTIST_URL, query_type[\"simple\"], \"f90e8b26-9e52-4669-a5c9-e28529c47894\")\n",
    "\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"first aid kit\")\n",
    "    count = 0\n",
    "    for artist in results[\"artists\"]:\n",
    "        if artist[\"name\"].lower().strip() == \"first aid kit\":\n",
    "            count += 1\n",
    "    \n",
    "    print(\"Number of bands named First Aid Kid:\",count)\n",
    "    \n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"queen\")\n",
    "    print(\"Begin area for Queen:\",results[\"artists\"][0][\"begin-area\"][\"name\"])\n",
    "\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"beatles\")\n",
    "    \n",
    "    for alias in results[\"artists\"][0][\"aliases\"]:\n",
    "        if alias[\"locale\"] == \"es\":\n",
    "            aliasname = alias[\"name\"]\n",
    "    \n",
    "    print(\"Spanish alias of Beatles:\",aliasname)\n",
    "    \n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Nirvana\")\n",
    "    print(\"Nirvana disambiguation\",results[\"artists\"][0][\"disambiguation\"])\n",
    "    \n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"One Direction\")\n",
    "    print(\"One direction est.:\",results[\"artists\"][0][\"life-span\"][\"begin\"])\n",
    "\n",
    "\n",
    "    \n",
    "#     artist_id = results[\"artists\"][0][\"id\"]\n",
    "\n",
    "#     pretty_print(results[\"artists\"][0])\n",
    "\n",
    "#     artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "#     releases = artist_data[\"releases\"]\n",
    "\n",
    "#     pretty_print(releases[0], indent=2)\n",
    "#     release_titles = [r[\"title\"] for r in releases]\n",
    "\n",
    "\n",
    "#     for t in release_titles:\n",
    "#         print(t)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825dd9fc-7713-44e0-8b7a-775d6bb1e019\n",
      "{\n",
      "  \"barcode\": \"606949003821\",\n",
      "  \"country\": \"US\",\n",
      "  \"date\": \"1996-09-12\",\n",
      "  \"disambiguation\": \"\",\n",
      "  \"id\": \"08130990-ae9f-4cbf-86d3-54409a55f530\",\n",
      "  \"packaging\": \"Jewel Case\",\n",
      "  \"packaging-id\": \"ec27701a-4a22-37f4-bfac-6616e0f9750a\",\n",
      "  \"quality\": \"normal\",\n",
      "  \"release-events\": [\n",
      "    {\n",
      "      \"area\": {\n",
      "        \"disambiguation\": \"\",\n",
      "        \"id\": \"489ce91b-6658-3307-9877-795b68554c98\",\n",
      "        \"iso-3166-1-codes\": [\n",
      "          \"US\"\n",
      "        ],\n",
      "        \"name\": \"United States\",\n",
      "        \"sort-name\": \"United States\"\n",
      "      },\n",
      "      \"date\": \"1996-09-12\"\n",
      "    }\n",
      "  ],\n",
      "  \"status\": \"Official\",\n",
      "  \"status-id\": \"4e304316-386d-3409-af2e-78857eec5cfe\",\n",
      "  \"text-representation\": {\n",
      "    \"language\": \"eng\",\n",
      "    \"script\": \"Latn\"\n",
      "  },\n",
      "  \"title\": \"Tha Doggfather\"\n",
      "}\n",
      "Tha Doggfather\n",
      "No Limit Top Dogg\n",
      "The Next Episode\n",
      "Da Game Is to Be Sold, Not to Be Told\n",
      "What's My Name?\n",
      "Snoop's Upside Ya Head\n",
      "What's My Name\n",
      "The Next Episode\n",
      "Gin & Juice\n",
      "Tha Doggfather\n",
      "Deep Cover\n",
      "Never Leave Me Alone\n",
      "Doggystyle\n",
      "G'd Up\n",
      "Doggystyle\n",
      "Doggystyle\n",
      "Tha Doggfather\n",
      "Still D.R.E.\n",
      "Doggystyle\n",
      "No Limit Top Dogg\n",
      "Doggy Dogg World\n",
      "Smokefest\n",
      "Deep Cover\n",
      "Doggystyle\n",
      "Da Game Is to Be Sold, Not to Be Told\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Snoop Dogg\")\n",
    "#pretty_print(results)\n",
    "\n",
    "artist_id = results[\"artists\"][0][\"id\"]\n",
    "\n",
    "pretty_print(results[\"artists\"][1][\"id\"])\n",
    "\n",
    "artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "releases = artist_data[\"releases\"]\n",
    "\n",
    "pretty_print(releases[0], indent=2)\n",
    "release_titles = [r[\"title\"] for r in releases]\n",
    "\n",
    "for t in release_titles:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set: Data extraction fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUIZ: Using CSV Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#QUIZ: Using CSV Module\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is to process the supplied file and use the csv module to extract data from it.\n",
    "The data comes from NREL (National Renewable Energy Laboratory) website. Each file\n",
    "contains information from one meteorological station, in particular - about amount of\n",
    "solar and wind energy for each hour of day.\n",
    "\n",
    "Note that the first line of the datafile is neither data entry, nor header. It is a line\n",
    "describing the data source. You should extract the name of the station from it.\n",
    "\n",
    "The data should be returned as a list of lists (not dictionaries).\n",
    "You can use the csv modules \"reader\" method to get data in such format.\n",
    "Another useful method is next() - to get the next line from the iterator.\n",
    "You should only change the parse_file function.\n",
    "\"\"\"\n",
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"745090.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    with open(datafile, 'r') as sd:\n",
    "        first_line = next(sd)\n",
    "        name = list(first_line.split(','))[1].strip('\"')       \n",
    "\n",
    "        r = csv.reader(sd,delimiter=',')\n",
    "        next(r)\n",
    "        \n",
    "        for line in r:\n",
    "            data.append(line)\n",
    "    \n",
    "    return (name, data)\n",
    "    \n",
    "\n",
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUIZ: Excel to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#QUIZ: Excel to CSV\n",
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "\n",
    "\n",
    "# Each Excel sheet in a Python dictionary\n",
    "    workbook = pd.ExcelFile(datafile)\n",
    "\n",
    "    for sheet_name in workbook.sheet_names:\n",
    "        df = workbook.parse(sheet_name)\n",
    "        \n",
    "    max_values = df.max()\n",
    "    stations = list(['COAST', 'EAST', 'FAR_WEST', 'NORTH','NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST'])\n",
    "    dict_max = {}\n",
    "\n",
    "    for station in stations:\n",
    "        max_val = max_values[station]\n",
    "        max_time = pd.DatetimeIndex(df[df[station] == max_val]['Hour_End'])\n",
    "        year = max_time.year.item()\n",
    "        month = max_time.month.item()\n",
    "        day = max_time.day.item()\n",
    "        hour = max_time.hour.item()\n",
    "\n",
    "        dict_max[station] = year,month,day,hour,max_val\n",
    "    \n",
    "    data = pd.DataFrame.from_dict(dict_max,orient='index').reset_index()\n",
    "    data.rename(columns={'index':'Station',0:'Year',1:'Month',2:'Day',3:'Hour',4:'Max Load'}, inplace=True)\n",
    "    # YOUR CODE HERE\n",
    "    # Remember that you can use xlrd.xldate_as_tuple(sometime, 0) to convert\n",
    "    # Excel date to Python tuple of (year, month, day, hour, minute, second)\n",
    "    return data\n",
    "\n",
    "def save_file(data, filename):\n",
    "    data.to_csv(filename,sep='|', encoding='utf-8',index=False)\n",
    "    \n",
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            station = line['Station']\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Solution from video. As expected, completely different\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    data = {}\n",
    "    # process all rows that contain station data\n",
    "    for n in range (1, 9):\n",
    "        station = sheet.cell_value(0, n)\n",
    "        cv = sheet.col_values(n, start_rowx=1, end_rowx=None)\n",
    "\n",
    "        maxval = max(cv)\n",
    "        maxpos = cv.index(maxval) + 1\n",
    "        maxtime = sheet.cell_value(maxpos, 0)\n",
    "        realtime = xlrd.xldate_as_tuple(maxtime, 0)\n",
    "        data[station] = {\"maxval\": maxval,\n",
    "                         \"maxtime\": realtime}\n",
    "\n",
    "    print data\n",
    "    return data\n",
    "\n",
    "def save_file(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        w = csv.writer(f, delimiter='|')\n",
    "        w.writerow([\"Station\", \"Year\", \"Month\", \"Day\", \"Hour\", \"Max Load\"])\n",
    "        for s in data:\n",
    "            year, month, day, hour, _ , _= data[s][\"maxtime\"]\n",
    "            w.writerow([s, year, month, day, hour, data[s][\"maxval\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUIZ: Wrangling JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#QUIZ: Wrangling JSON"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
