{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generating sample for initial exploration. Code (minus path changes) provided by Udacity project description\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"data/bergen.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"data/sample.osm\"\n",
    "\n",
    "k = 20 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'osm': 1, 'tag': 515044, 'bounds': 1, 'nd': 636272, 'relation': 2595, 'member': 21241, 'way': 52393, 'node': 628779}\n"
     ]
    }
   ],
   "source": [
    "#tag count of dataset\n",
    "\n",
    "with open('data/bergen.osm') as f:\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    tag_dict = {}\n",
    "    \n",
    "    for line in root.iter():\n",
    "        tag = line.tag\n",
    "        \n",
    "        tag_dict[tag] = tag_dict.get(tag, 0) + 1\n",
    "        \n",
    "    print(tag_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generating list of all Bergen street names as of 2005. Source: Wikipedia.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "bergen_street_names = []\n",
    "\n",
    "r = requests.get('https://no.wikipedia.org/wiki/Liste_over_Bergens_gater')\n",
    "\n",
    "wiki_soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "street_div = wiki_soup.find(id='mw-content-text')\n",
    "\n",
    "for name in street_div.find_all('li'):\n",
    "    #Åstveitveien is the last name of the page, so stopping after that row to avoid bad data entries\n",
    "    if name.string == 'Åstveitveien':\n",
    "        bergen_street_names.append(name.string)\n",
    "        break\n",
    "    else:\n",
    "        bergen_street_names.append(name.string)\n",
    "    \n",
    "\n",
    "#Defining search query for characters that should not be found in street names\n",
    "problemchars = re.compile(r'[=\\+/&<>;\"\\?%#$@\\,:<>\\t\\r\\n]')\n",
    "\n",
    "#Removing incorrect items from street name list. Printing them out for transparency/QA.\n",
    "for item in bergen_street_names:\n",
    "    if problemchars.search(item):\n",
    "        print('PROBLEM STREET NAME:',item)\n",
    "        print('DELETING NAME', bergen_street_names[count], 'FROM STREET NAME LIST.')\n",
    "        del(bergen_street_names[count])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will audit the quality of the street names in the data set. One tricky part is that Norwegian street names are concatenated with no clear distinction between the different words. For example, the equivalent of Main Street is Hovedgaten.\n",
    "\n",
    "Due to this the main audit criteria will be whether the name exists in the Bergen street name list generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eien 1': {'Laguneveien 1'},\n",
      " 's Gate': {'Thormøhlens Gate'},\n",
      " 'øgda 9': {'Smøråshøgda 9'}}\n"
     ]
    }
   ],
   "source": [
    "#Auditing street name quiality\n",
    "\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "#Auditing street names\n",
    "\n",
    "OSMFILE = \"data/bergen.osm\"\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib.setdefault('k',None) == \"addr:street\")\n",
    "\n",
    "street_types = defaultdict(set)\n",
    "\n",
    "expected = [\"gate\", \"gaten\", \"vei\", \"veien\", \"veg\", \"vegen\", \"lien\", \"neset\", \"smauet\", \"allé\",\n",
    "           \"høgda\", \"plass\", \"dalen\", \"haugen\", \"myra\"]\n",
    "expected_long = [\"allmenningen\", \"fjorden\",\"Flagget\",\"Smålonane\",\"Tangen\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "\n",
    "    valid = 0\n",
    "    street_type = street_name[-6::]\n",
    "    \n",
    "    if street_name in bergen_street_names:\n",
    "        valid = 1\n",
    "    \n",
    "    else:\n",
    "        for s_type in expected:\n",
    "\n",
    "            if s_type in street_type:\n",
    "                valid = 1\n",
    "            else:\n",
    "                for name in expected_long:\n",
    "                    if street_type in name:\n",
    "                        valid = 1                    \n",
    "\n",
    "    if valid == 0:\n",
    "        street_types[street_type].add(street_name)\n",
    "            \n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print('{0}: {1}'.format(k, v))\n",
    "\n",
    "def audit():\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    pprint(dict(street_types))\n",
    "            \n",
    "            \n",
    "audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Laguneveien 1': 'Laguneveien',\n",
       " 'Smøråshøgda 9': 'Smøråshøgda',\n",
       " 'Thormøhlens Gate': 'Thormøhlens gate'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Improving names\n",
    "\n",
    "mapping = { \"Gate\": \"gate\",\n",
    "            }\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    m = street_type_re.search(name)\n",
    "    street_type = m.group()\n",
    "    \n",
    "    if street_type in mapping.keys():\n",
    "        name = re.sub(street_type,mapping[street_type],name)\n",
    "\n",
    "    return name\n",
    "\n",
    "def generate_new_names(street_types):\n",
    "    better_names = {}\n",
    "    for st_type, ways in street_types.items():\n",
    "\n",
    "        for old_name in ways:\n",
    "            \n",
    "            #if old_name ends in street number, remove street number\n",
    "            if re.search(' [0-9]*$',old_name):\n",
    "                better_name = re.sub(' [0-9]*$','',old_name)\n",
    "                \n",
    "            else:\n",
    "                better_name = update_name(old_name, mapping)\n",
    "            better_names[old_name] = better_name\n",
    "            \n",
    "    return better_names\n",
    "\n",
    "generate_new_names(street_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"test.json\", \"w\") as fo:\n",
    "    fo.write(json.dumps(\"bradæ å æ\", ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above 100\n",
      "above 1000\n",
      "above 10000\n",
      "{'created': {'changeset': '6007582',\n",
      "             'timestamp': '2010-10-10T22:30:34Z',\n",
      "             'uid': '114230',\n",
      "             'user': 'danerikk',\n",
      "             'version': '2'},\n",
      " 'id': '358065',\n",
      " 'pos': [60.5320227, 5.2557628],\n",
      " 'type': 'node'}\n",
      "{'node_refs': ['3799466707', '3799466661', '3799466708', '3799466731', '3799466735', '3799466733', '3799466740', '1850625657', '3799466869', '3799466751', '3799466707'], 'type': 'way', 'address': {'city': 'Bergen', 'housenumber': '13', 'postcode': '5003', 'street': 'Øvregaten'}, 'id': '376535335', 'ref': '3799466707', 'created': {'changeset': '34822543', 'timestamp': '2015-10-23T15:11:21Z', 'user': 'daviesp12', 'uid': '722193', 'version': '1'}}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-47cd940dd441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-47cd940dd441>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcorrect_first_elem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     assert data[-1][\"address\"] == {\n\u001b[1;32m    179\u001b[0m                                     \u001b[0;34m\"street\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"West Lexington St.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Quiz: Preparing for database - MongoDB\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "multi_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*:(.)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "# el = shape_element(element)\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        \n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        node['type'] = element.tag\n",
    "\n",
    "        created = dict()\n",
    "        address = dict()\n",
    "        colon_dict = dict()\n",
    "        node_refs = list()\n",
    "        \n",
    "        for nod in element.iter():  \n",
    "            if element.tag == 'way' and nod.tag == 'nd':\n",
    "                node_refs.append(nod.attrib['ref'])\n",
    "                \n",
    "            for k,v in nod.attrib.items():\n",
    "            \n",
    "                if 'k' in nod.keys():\n",
    "                    node_key = nod.attrib['k']\n",
    "                    node_val = nod.attrib['v']\n",
    "                else:\n",
    "                    node_key = ''\n",
    "                    node_val = ''\n",
    "            \n",
    "                node_keys = nod.keys()\n",
    "                node_vals = nod.attrib\n",
    "\n",
    "                if problemchars.search(node_key):\n",
    "                    pass\n",
    "\n",
    "                elif re.match('addr:',node_key):\n",
    "                    k_list = node_key.rstrip(':').split(':')[1:]\n",
    "                    k_len =  len(k_list)\n",
    "         \n",
    "                    if k_len == 1:   \n",
    "                        address[k_list[0]] = node_val\n",
    "                    elif k_len == 2 and k_list[0] == 'street':\n",
    "                        pass\n",
    "                    \n",
    "                    elif k_len > 1:\n",
    "                        print(('RECHECK ADDRESS, UNEXPECTED  VARIABLE COUNT: {0}, {1}').format(k_len,k_list))\n",
    "                \n",
    "    \n",
    "                elif lower_colon.search(node_key):\n",
    "                    colon_dict[node_key] = node_val\n",
    "                \n",
    "                                \n",
    "                elif k in ('k','v'):\n",
    "                    pass\n",
    "                \n",
    "                elif k in CREATED:\n",
    "                    created[k] = v\n",
    "                    \n",
    "                elif k == 'lat':\n",
    "                    lat = float(v)\n",
    "                elif k == 'lon':\n",
    "                    lon = float(v)\n",
    "\n",
    "                else:    \n",
    "                   \n",
    "                    node[k] = v\n",
    "                \n",
    "                \n",
    "            \n",
    "            if 'lat' in nod.attrib.keys():\n",
    "                node['pos'] = [lat,lon]\n",
    "\n",
    "        node['created'] = created\n",
    "        \n",
    "        if len(node_refs) != 0:\n",
    "            node['node_refs'] = node_refs\n",
    "\n",
    "        if len(address) != 0:\n",
    "                node['address'] = {}\n",
    "                for key in address.keys():\n",
    "                    node['address'][key] = address[key]\n",
    "\n",
    "        if len(colon_dict) > 0:\n",
    "\n",
    "            for k in colon_dict:\n",
    "                k_list = k.rstrip(':').split(':')\n",
    "                if len(k_list) ==  2:\n",
    "                    node[k_list[0]] = {k_list[1] : colon_dict[k]} \n",
    "                    \n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            \n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if count == 100:\n",
    "                print(\"above 100\")\n",
    "            elif count == 1000:\n",
    "                print(\"above 1000\")\n",
    "            elif count == 10000:\n",
    "                print(\"above 10000\")\n",
    "            elif count == 100000:\n",
    "                print(\"above 100000\")            \n",
    "            \n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    #Turning off ascii control to allow Norwegian letters æøå\n",
    "                    fo.write(json.dumps(el, indent=2, ensure_ascii=False)+\"\\n\")\n",
    "                else:\n",
    "                    #Turning off ascii control to allow Norwegian letters æøå\n",
    "                    fo.write(json.dumps(el,ensure_ascii=False) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "def test():\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map('data/sample.osm', False)\n",
    "#     pprint(data)   \n",
    "    \n",
    "    correct_first_elem = {\n",
    "        \"id\": \"261114295\", \n",
    "        \"visible\": \"true\", \n",
    "        \"type\": \"node\", \n",
    "        \"pos\": [41.9730791, -87.6866303], \n",
    "        \"created\": {\n",
    "            \"changeset\": \"11129782\", \n",
    "            \"user\": \"bbmiller\", \n",
    "            \"version\": \"7\", \n",
    "            \"uid\": \"451048\", \n",
    "            \"timestamp\": \"2012-03-28T18:31:23Z\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    pprint(data[0])\n",
    "#     pprint(data[-10:-1])\n",
    "    \n",
    "    for row in data:\n",
    "        if row['id'] == \"376535335\":\n",
    "            print(row)\n",
    "    \n",
    "    assert data[0] == correct_first_elem\n",
    "    assert data[-1][\"address\"] == {\n",
    "                                    \"street\": \"West Lexington St.\", \n",
    "                                    \"housenumber\": \"1412\"\n",
    "                                      }\n",
    "    assert data[-1][\"node_refs\"] == [ \"2199822281\", \"2199822390\",  \"2199822392\", \"2199822369\", \n",
    "                                    \"2199822370\", \"2199822284\", \"2199822281\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "For downloading map data: \n",
    "- https://mapzen.com/data/metro-extracts/ \n",
    "- https://mapzen.com/documentation/metro-extracts/file-format/ \n",
    "\n",
    "http://www.openstreetmap.org/relation/404159#map=10/60.3572/5.4163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken:  \n",
    "1. Clean street names  \n",
    "2. Generate json file from sample file  \n",
    "3. While reviewing the output file I noticed that the Norwegian characters æøå was not encoded correctly. After debugging for a while I figured out that the error happened in the json module when running json.dumps(). Setting ensure_ascii = False solved this.\n",
    "\n",
    "Steps to go:\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
