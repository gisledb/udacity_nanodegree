{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Generating sample for initial exploration. Code (minus path changes) provided by Udacity project description\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"data/bergen.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"data/sample.osm\"\n",
    "\n",
    "k = 20 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'way': 52393, 'osm': 1, 'node': 628779, 'tag': 515044, 'nd': 636272, 'member': 21241, 'bounds': 1, 'relation': 2595}\n"
     ]
    }
   ],
   "source": [
    "#tag count of dataset\n",
    "\n",
    "with open('data/bergen.osm') as f:\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    tag_dict = {}\n",
    "    \n",
    "    for line in root.iter():\n",
    "        tag = line.tag\n",
    "        \n",
    "        tag_dict[tag] = tag_dict.get(tag, 0) + 1\n",
    "        \n",
    "    print(tag_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO-5035: 1\n",
      "NO-5059: 3\n"
     ]
    }
   ],
   "source": [
    "#Auditing postcode quality\n",
    "\n",
    "OSMFILE = \"data/bergen.osm\"\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.attrib.setdefault('k',None) == \"addr:postcode\")\n",
    "\n",
    "error_postcodes = defaultdict(int)\n",
    "\n",
    "def audit_postcodes(error_postcodes, postcode):\n",
    "    \n",
    "    if len(postcode) == 4:\n",
    "        try:\n",
    "            int(postcode)\n",
    "        except TypeError:\n",
    "            error_postcodes[postcode] += 1\n",
    "    else:\n",
    "        error_postcodes[postcode] += 1\n",
    "            \n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print('{0}: {1}'.format(k, v))\n",
    "\n",
    "def audit():\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag in [\"way\",\"node\"]:\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postcode(tag):\n",
    "                    audit_postcodes(error_postcodes, tag.attrib['v'])\n",
    "                                        \n",
    "    print_sorted_dict(error_postcodes)\n",
    "    \n",
    "    \n",
    "audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Generating list of all Bergen street names as of 2005. Source: Wikipedia.\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "bergen_street_names = []\n",
    "\n",
    "r = requests.get('https://no.wikipedia.org/wiki/Liste_over_Bergens_gater')\n",
    "\n",
    "wiki_soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "street_div = wiki_soup.find(id='mw-content-text')\n",
    "\n",
    "for name in street_div.find_all('li'):\n",
    "    #Åstveitveien is the last name of the page, so stopping after that row to avoid bad data entries\n",
    "    if name.string == 'Åstveitveien':\n",
    "        bergen_street_names.append(name.string)\n",
    "        break\n",
    "    else:\n",
    "        bergen_street_names.append(name.string)\n",
    "    \n",
    "\n",
    "#Defining search query for characters that should not be found in street names\n",
    "problemchars = re.compile(r'[=\\+/&<>;\"\\?%#$@\\,:<>\\t\\r\\n]')\n",
    "\n",
    "#Removing incorrect items from street name list. Printing them out for transparency/QA.\n",
    "\n",
    "count = -1\n",
    "\n",
    "for item in bergen_street_names:\n",
    "    count += 1\n",
    "    if problemchars.search(item):\n",
    "        print('PROBLEM STREET NAME:',item)\n",
    "        print('DELETING NAME', bergen_street_names[count], 'FROM STREET NAME LIST.')\n",
    "        del(bergen_street_names[count])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Wikipedia list consists of data provided by the Norwegian Mapping Authority. Since it's somewhat dated (2005), I decided to look for more publically available datasets. After a little research I discovered that the Norwegian Public Roads Administration (NPRA) has a public API which contains street name data for all of Norway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Generating street name list from the The Norwegian Public Roads Administration API\n",
    "\n",
    "def bergen_streets_list():\n",
    "    print('Start processing 1st call')\n",
    "    bergen_streets = list()\n",
    "    start = None\n",
    "    count = 0\n",
    "    types = set()\n",
    "    \n",
    "    def get_bergen_streets(start=None):\n",
    "\n",
    "        url = 'https://www.vegvesen.no/nvdb/api/v2/vegobjekter/538'\n",
    "\n",
    "        if start:\n",
    "            payload = {'inkluder': 'egenskaper', 'kommune': '1201','antall': '1000', 'start': start}\n",
    "        else:\n",
    "            #Hard to debug error when the initial limit was set to 1000. Lowering it to 200 works without issues.\n",
    "            payload = {'inkluder': 'egenskaper', 'kommune': '1201','antall': '200'}\n",
    "        headers = {'content-type': 'application/vnd.vegvesen.nvdb-v2+json'}\n",
    "        r = requests.get(url, params=payload, headers=headers)\n",
    "\n",
    "        return r\n",
    "\n",
    "\n",
    "    def streets_list(start=None):\n",
    "\n",
    "        nonlocal count\n",
    "        count += 1\n",
    "        response = get_bergen_streets(start)\n",
    "#         global debug_response\n",
    "#         debug_response = response\n",
    "\n",
    "    #     json = get_bergen_streets()\n",
    "        objects = response.json()['objekter']\n",
    "        metadata = response.json()['metadata']\n",
    "        print(\"Received batch no.\",count)\n",
    "\n",
    "        if metadata['returnert'] != 0:\n",
    "\n",
    "            start = metadata['neste']['start']\n",
    "            for object in objects:\n",
    "                \n",
    "                for attribute in object['egenskaper']:\n",
    "                    types.add(attribute['navn'])\n",
    "                    if attribute['navn'] == 'Gatenavn':\n",
    "                        bergen_streets.append(attribute['verdi'])\n",
    "\n",
    "#                     for k,v in object['egenskaper'][1].items():\n",
    "#                         print(k,v)\n",
    "#                     print('----------------')\n",
    "            \n",
    "            print(\"Completed processing of batch no.\",count)\n",
    "            streets_list(start=start)\n",
    "            \n",
    "    streets_list()            \n",
    "    print(\"Attribute types:\",types)\n",
    "    print(\"Completed API calls and processing. Returning list with {} street names.\".format(len(bergen_streets)))\n",
    "    return bergen_streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing 1st call\n",
      "Received batch no. 1\n",
      "Completed processing of batch no. 1\n",
      "Received batch no. 2\n",
      "Completed processing of batch no. 2\n",
      "Received batch no. 3\n",
      "Completed processing of batch no. 3\n",
      "Received batch no. 4\n",
      "Completed processing of batch no. 4\n",
      "Received batch no. 5\n",
      "Completed processing of batch no. 5\n",
      "Received batch no. 6\n",
      "Completed processing of batch no. 6\n",
      "Received batch no. 7\n",
      "Attribute types: {'Gatekode', 'Gatenavn', 'Sideveg'}\n",
      "Completed API calls and processing. Returning list with 4295 street names.\n"
     ]
    }
   ],
   "source": [
    "bergen_streets = bergen_streets_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1878"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for duplicates in the NPRA list\n",
    "nrpa_set = set()\n",
    "\n",
    "for street in bergen_streets:\n",
    "    nrpa_set.add(street)\n",
    "    \n",
    "len(nrpa_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street names in the wikipedia list not found in NRPA list: 215\n",
      "Street names in the NRPA list not found in wikipedia list: 201\n"
     ]
    }
   ],
   "source": [
    "#Comparing the street names from the different data providers\n",
    "\n",
    "wikipedia_set = set(bergen_street_names)\n",
    "\n",
    "print(\"Street names in the wikipedia list not found in NRPA list:\",len(wikipedia_set - nrpa_set) )\n",
    "print(\"Street names in the NRPA list not found in wikipedia list:\",len(nrpa_set - wikipedia_set) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next I will audit the quality of the street names in the data set. One tricky part is that Norwegian street names are concatenated with no clear distinction between the different words. For example, the equivalent of Main Street is Hovedgaten.\n",
    "\n",
    "Due to this the main audit criteria will be whether the name exists in the Bergen street name lists sourced from the Wikipedia and NPRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2093"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining street names from both street name lists\n",
    "bergen_set = nrpa_set | wikipedia_set\n",
    "\n",
    "len(bergen_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_street_name(streetname):\n",
    "    OSMFILE = \"data/bergen.osm\"\n",
    "    \n",
    "    def is_street_name(elem):\n",
    "        return (elem.attrib.setdefault('k',None) == \"addr:street\")\n",
    "\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag in (\"node\", \"way\"):\n",
    "            for tag in elem.iter():\n",
    "                if is_street_name(tag):\n",
    "                    if tag.attrib['v'] == streetname:\n",
    "                        return event,elem.iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def return_all_cities():\n",
    "    OSMFILE = \"data/bergen.osm\"\n",
    "    return_dict = defaultdict(int)\n",
    "    \n",
    "    def city(elem):\n",
    "        return (elem.attrib.setdefault('k',None) == \"addr:city\")\n",
    "\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag in (\"node\", \"way\"):\n",
    "            for tag in elem.iter():\n",
    "                if city(tag):\n",
    "                    return_dict[tag.attrib['v']] += 1\n",
    "    \n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Ask': 960,\n",
       "             'Bergen': 18156,\n",
       "             'Bjørndalstræ': 554,\n",
       "             'Bjørøyhamn': 435,\n",
       "             'Blomsterdalen': 1221,\n",
       "             'Brattholmen': 722,\n",
       "             'Breistein': 390,\n",
       "             'Bønes': 2646,\n",
       "             'Eidsvåg i Åsane': 474,\n",
       "             'Eidsvågneset': 503,\n",
       "             'Erdal': 1071,\n",
       "             'FREKHAUG': 1,\n",
       "             'Fana': 1988,\n",
       "             'Flaktveit': 1393,\n",
       "             'Florvåg': 1016,\n",
       "             'Follese': 479,\n",
       "             'Frekhaug': 1727,\n",
       "             'Fyllingsdalen': 4424,\n",
       "             'Godvik': 1725,\n",
       "             'Hauglandshella': 1372,\n",
       "             'Haukeland': 125,\n",
       "             'Hetlevik': 372,\n",
       "             'Hjellestad': 1030,\n",
       "             'Hordvik': 819,\n",
       "             'Hylkje': 511,\n",
       "             'KLEPPESTØ': 2,\n",
       "             'Kalandseidet': 443,\n",
       "             'Kleppestø': 2751,\n",
       "             'Klokkarvik': 288,\n",
       "             'Knarrevik': 910,\n",
       "             'Kokstad': 221,\n",
       "             'Kolltveit': 234,\n",
       "             'Laksevåg': 3084,\n",
       "             'Loddefjord': 2188,\n",
       "             'Lysekloster': 70,\n",
       "             'Mathopen': 1134,\n",
       "             'Mjølkeråen': 962,\n",
       "             'Morvik': 1044,\n",
       "             'Nesttun': 5813,\n",
       "             'Nyborg': 1665,\n",
       "             'Olsvik': 1015,\n",
       "             'Paradis': 1781,\n",
       "             'Rong': 1,\n",
       "             'Rådal': 4878,\n",
       "             'STRUSSHAMN': 19,\n",
       "             'Salhus': 336,\n",
       "             'Sandsli': 1517,\n",
       "             'Straume': 307,\n",
       "             'Straumsgrend': 748,\n",
       "             'Strusshamn': 1042,\n",
       "             'Søfteland': 270,\n",
       "             'Søreidgrend': 2253,\n",
       "             'Tertnes': 1356,\n",
       "             'Ulset': 2201,\n",
       "             'Valestrandsfossen': 1,\n",
       "             'Ytre Arna': 906,\n",
       "             'Øvre Ervik': 606})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_count = return_all_cities()\n",
    "\n",
    "city_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frekhaug': 2, 'kleppestø': 2, 'strusshamn': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I see some duplicates above, writing function to identify them\n",
    "def find_key_duplicates(dictionary):\n",
    "    keys = dictionary.keys()\n",
    "    new_dict = defaultdict(int)\n",
    "    for key in keys:\n",
    "        new_dict[key.lower()] += 1\n",
    "    \n",
    "    dup_dict = dict()\n",
    "    \n",
    "    for key,val in new_dict.items():\n",
    "        if val > 1:\n",
    "            dup_dict[key] = val\n",
    "            \n",
    "    return dup_dict\n",
    "            \n",
    "        \n",
    "find_key_duplicates(city_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged Strusshamn value: 1061\n",
      "merged Frekhaug value: 1728\n",
      "merged Kleppestø value: 2753\n",
      "old_values: {'Kleppestø': 2751, 'Frekhaug': 1727, 'Strusshamn': 1042}\n"
     ]
    }
   ],
   "source": [
    "#Writing function to merge uppercased keys with capitalized keys\n",
    "def merge_keys(dictionary):\n",
    "    keys = find_key_duplicates(dictionary).keys()\n",
    "    \n",
    "    old_values = dict()\n",
    "    \n",
    "    for key in keys:\n",
    "        capitalized = key.capitalize()\n",
    "        uppercased =  key.upper()\n",
    "        \n",
    "        old_values[capitalized] = dictionary[capitalized]\n",
    "        \n",
    "        dictionary[key.capitalize()] = dictionary[capitalized] + dictionary[uppercased]\n",
    "        del dictionary[uppercased]\n",
    "        print(\"merged {0} value: {1}\".format(capitalized,dictionary[capitalized]))\n",
    "\n",
    "    print(\"old_values:\",old_values)\n",
    "\n",
    "merge_keys(city_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Looking at all the cities in the dataset, it becomes clear that quite a few of them do not belong to Bergen municipality. Many, maybe most of them, do though. \n",
    "\n",
    "Since I am primarily focusing on Bergen I am making the decision to only clean street names within Bergen municipality. The Norwegian postal service provides a downloadble list on their website with overview of postal codes, cities and municipality they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>postal_place</th>\n",
       "      <th>muni_number</th>\n",
       "      <th>muni_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0010</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>301</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0015</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>301</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>301</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>301</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0024</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>301</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  postal_code postal_place  muni_number muni_name category\n",
       "0        0010         OSLO          301      OSLO        B\n",
       "1        0015         OSLO          301      OSLO        B\n",
       "2        0018         OSLO          301      OSLO        G\n",
       "3        0021         OSLO          301      OSLO        P\n",
       "4        0024         OSLO          301      OSLO        P"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "postcodes_per_municipality = pd.read_csv('data/Postnummerregister_ansi.tsv', encoding='utf-8',delimiter='\\t',header=0, names=[\n",
    "        'postal_code','postal_place','muni_number','muni_name','category'],\n",
    "            dtype = {'postal_code': str, 'municipality_number': str})\n",
    "\n",
    "postcodes_per_municipality.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bergen_postcodes = postcodes_per_municipality[['postal_code','postal_place']][postcodes_per_municipality['muni_name'] == 'BERGEN']\n",
    "bergen_postcodes['postal_place'] = bergen_postcodes['postal_place'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>postal_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>5003</td>\n",
       "      <td>bergen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>5004</td>\n",
       "      <td>bergen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>5005</td>\n",
       "      <td>bergen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>5006</td>\n",
       "      <td>bergen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>5007</td>\n",
       "      <td>bergen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     postal_code postal_place\n",
       "2581        5003       bergen\n",
       "2582        5004       bergen\n",
       "2583        5005       bergen\n",
       "2584        5006       bergen\n",
       "2585        5007       bergen"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bergen_postcodes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bergen</th>\n",
       "      <td>18156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nesttun</th>\n",
       "      <td>5813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rådal</th>\n",
       "      <td>4878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fyllingsdalen</th>\n",
       "      <td>4424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laksevåg</th>\n",
       "      <td>3084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kleppestø</th>\n",
       "      <td>2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bønes</th>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søreidgrend</th>\n",
       "      <td>2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ulset</th>\n",
       "      <td>2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loddefjord</th>\n",
       "      <td>2188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fana</th>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paradis</th>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frekhaug</th>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>godvik</th>\n",
       "      <td>1725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyborg</th>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandsli</th>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flaktveit</th>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hauglandshella</th>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tertnes</th>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blomsterdalen</th>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathopen</th>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erdal</th>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strusshamn</th>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morvik</th>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hjellestad</th>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florvåg</th>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olsvik</th>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mjølkeråen</th>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knarrevik</th>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ytre arna</th>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hordvik</th>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>straumsgrend</th>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brattholmen</th>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>øvre ervik</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bjørndalstræ</th>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hylkje</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eidsvågneset</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follese</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eidsvåg i åsane</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kalandseidet</th>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bjørøyhamn</th>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breistein</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hetlevik</th>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salhus</th>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>straume</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>klokkarvik</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søfteland</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kolltveit</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kokstad</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haukeland</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lysekloster</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rong</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valestrandsfossen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "bergen             18156\n",
       "nesttun             5813\n",
       "rådal               4878\n",
       "fyllingsdalen       4424\n",
       "laksevåg            3084\n",
       "kleppestø           2753\n",
       "bønes               2646\n",
       "søreidgrend         2253\n",
       "ulset               2201\n",
       "loddefjord          2188\n",
       "fana                1988\n",
       "paradis             1781\n",
       "frekhaug            1728\n",
       "godvik              1725\n",
       "nyborg              1665\n",
       "sandsli             1517\n",
       "flaktveit           1393\n",
       "hauglandshella      1372\n",
       "tertnes             1356\n",
       "blomsterdalen       1221\n",
       "mathopen            1134\n",
       "erdal               1071\n",
       "strusshamn          1061\n",
       "morvik              1044\n",
       "hjellestad          1030\n",
       "florvåg             1016\n",
       "olsvik              1015\n",
       "mjølkeråen           962\n",
       "ask                  960\n",
       "knarrevik            910\n",
       "ytre arna            906\n",
       "hordvik              819\n",
       "straumsgrend         748\n",
       "brattholmen          722\n",
       "øvre ervik           606\n",
       "bjørndalstræ         554\n",
       "hylkje               511\n",
       "eidsvågneset         503\n",
       "follese              479\n",
       "eidsvåg i åsane      474\n",
       "kalandseidet         443\n",
       "bjørøyhamn           435\n",
       "breistein            390\n",
       "hetlevik             372\n",
       "salhus               336\n",
       "straume              307\n",
       "klokkarvik           288\n",
       "søfteland            270\n",
       "kolltveit            234\n",
       "kokstad              221\n",
       "haukeland            125\n",
       "lysekloster           70\n",
       "rong                   1\n",
       "valestrandsfossen      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city_count = pd.DataFrame([city_count]).transpose()\n",
    "df_city_count.index = df_city_count.index.str.lower()\n",
    "df_city_count.columns = ['count']\n",
    "\n",
    "df_city_count.sort_values('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Bergen:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bjørøyhamn</th>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brattholmen</th>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erdal</th>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florvåg</th>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follese</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frekhaug</th>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hauglandshella</th>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hetlevik</th>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kleppestø</th>\n",
       "      <td>2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>klokkarvik</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knarrevik</th>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kolltveit</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lysekloster</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rong</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>straume</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strusshamn</th>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søfteland</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valestrandsfossen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "ask                  960\n",
       "bjørøyhamn           435\n",
       "brattholmen          722\n",
       "erdal               1071\n",
       "florvåg             1016\n",
       "follese              479\n",
       "frekhaug            1728\n",
       "hauglandshella      1372\n",
       "hetlevik             372\n",
       "kleppestø           2753\n",
       "klokkarvik           288\n",
       "knarrevik            910\n",
       "kolltveit            234\n",
       "lysekloster           70\n",
       "rong                   1\n",
       "straume              307\n",
       "strusshamn          1061\n",
       "søfteland            270\n",
       "valestrandsfossen      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found in dataset from Norway postal service:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>postal_place</th>\n",
       "      <th>muni_number</th>\n",
       "      <th>muni_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [postal_code, postal_place, muni_number, muni_name, category]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def postal_place_clarified():\n",
    "\n",
    "    unique_bergen = bergen_postcodes['postal_place'].unique()\n",
    "    unique_norway = postcodes_per_municipality['postal_place'].str.lower().unique()\n",
    "\n",
    "    outside_bergen = list()\n",
    "    not_in_postcode_dataset = list()\n",
    "    \n",
    "    for val in df_city_count.index:\n",
    "        \n",
    "        if val not in unique_bergen:\n",
    "            if val in unique_norway:\n",
    "                outside_bergen.append(val)\n",
    "            else:\n",
    "                not_in_postcode_dataset.append(val)\n",
    "        \n",
    "    print('Not in Bergen:')\n",
    "    display(df_city_count.loc[outside_bergen])\n",
    "    print('Not found in dataset from Norway postal service:')\n",
    "    display(postcodes_per_municipality[postcodes_per_municipality['postal_place'].isin(not_in_postcode_dataset)])\n",
    "    print(not_in_postcode_dataset)\n",
    "\n",
    "postal_place_clarified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "osm_file = 'data/sample.osm'\n",
    "\n",
    "# tree = ET.iterparse(osm_file, events=(\"start\",))\n",
    "\n",
    "tree = ET.parse(osm_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for child in root:\n",
    "    count+=1\n",
    "    if count < 10:\n",
    "        for tag in child:\n",
    "            print(tag.attr)#.find('addr:postcode')\n",
    "    else:\n",
    "        break\n",
    "# for event, elem in :\n",
    "#         if elem.tag == \"way\":\n",
    "#             for tag in elem.iter(\"tag\"):\n",
    "#                 if is_street_name(tag):\n",
    "#                     print(elem.\n",
    "#             pprint('----')\n",
    "            \n",
    "\n",
    "# def is_street_name(elem):\n",
    "#     return (elem.attrib['k'] == \"addr:street\")\n",
    "            \n",
    "# def is_street_name(elem):\n",
    "#     return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# def audit():\n",
    "#     for event, elem in ET.iterparse(osm_file):\n",
    "#         if is_street_name(elem):\n",
    "#             audit_street_type(street_types, elem.attrib['v'])    \n",
    "#     print_sorted_dict(street_types) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating sets to be used in next cell\n",
    "\n",
    "bergen_pc_set = bergen_postcodes['postal_code'].values\n",
    "norway_pc_set = postcodes_per_municipality['postal_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Auditing street names\n",
    "\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "#Auditing street names\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib.setdefault('k',None) == \"addr:street\")\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "# def is_in_bergen(elem):\n",
    "#     return elem.attrib['v'] in bergen_postcodes['postal_code']\n",
    "\n",
    "street_types = defaultdict(set)\n",
    "\n",
    "expected = [\"gate\", \"gaten\", \"vei\", \"veien\", \"veg\", \"vegen\", \"lien\", \"neset\", \"smauet\", \"allé\",\n",
    "           \"høgda\", \"plass\", \"dalen\", \"haugen\", \"myra\"]\n",
    "expected_long = [\"allmenningen\", \"fjorden\",\"Flagget\",\"Smålonane\",\"Tangen\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "\n",
    "    valid = 0\n",
    "    street_type = street_name[-6::]\n",
    "    \n",
    "    if street_name in bergen_set:\n",
    "        valid = 1\n",
    "    \n",
    "    else:\n",
    "        for s_type in expected:\n",
    "\n",
    "            if s_type in street_type:\n",
    "                valid = 1\n",
    "            else:\n",
    "                for name in expected_long:\n",
    "                    if street_type in name:\n",
    "                        valid = 1                    \n",
    "\n",
    "    if valid == 0:\n",
    "        street_types[street_type].add(street_name)\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "            \n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print('{0}: {1}'.format(k, v))\n",
    "\n",
    "OSMFILE = \"data/bergen.osm\"\n",
    "bergen_streets = set()\n",
    "outside_bergen = set()\n",
    "outside_norway = dict()\n",
    "no_postcode = list()\n",
    "        \n",
    "# def audit():\n",
    "        \n",
    "#     for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "# #         if elem.tag == \"way\":\n",
    "#         if elem.tag in (\"node\", \"way\"):\n",
    "#             for tag in elem.iter(\"tag\"):\n",
    "#                 if is_street_name(tag):\n",
    "#                     audit_street_type(street_types, tag.attrib['v'])\n",
    "#     pprint(dict(street_types))\n",
    "            \n",
    "def audit(osmfile):\n",
    "    \n",
    "    count = 0\n",
    "    postcode = ''\n",
    "    \n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):        \n",
    "        street = ''\n",
    "        postcode = ''\n",
    "        \n",
    "        if elem.tag in [\"way\", \"node\"]:\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    street = tag.attrib['v']\n",
    "#                     street_set.add(tag.attrib['v'])\n",
    "#                     street_list.append(tag.attrib['v'])\n",
    "                \n",
    "                if is_postcode(tag):\n",
    "                    postcode = tag.attrib['v'] \n",
    "    # TO DO: Add postcode check.       \n",
    "    \n",
    "        if street != '':\n",
    "            count += 1\n",
    "            if audit_street_type(street_types, street):\n",
    "                if postcode == '':\n",
    "                    no_postcode.append(street)\n",
    "                elif postcode in bergen_pc_set:\n",
    "                    bergen_streets.add(street)\n",
    "                elif postcode in norway_pc_set:\n",
    "                    outside_bergen.add(street)\n",
    "                else:\n",
    "                    outside_norway[street] = postcode\n",
    "                    \n",
    "    print(\"Total street names audited:\",count)\n",
    "            \n",
    "#             pprint(dict(street_types))\n",
    "#     print(\"list:\",len(street_list),\"set:\",len(street_set))\n",
    "    print(\"Bergen streets (distinct):\", len(bergen_streets))\n",
    "    print(\"Outside Bergen (distinct):\", len(outside_bergen))\n",
    "    print(\"Outside Norway:\", len(outside_norway))\n",
    "    print(\"missing postcode:\", len(no_postcode))\n",
    "    print(\"Total error streets:\", len(street_types))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total street names audited: 84000\n",
      "Bergen streets (distinct): 15\n",
      "Outside Bergen (distinct): 200\n",
      "Outside Norway: 0\n",
      "missing postcode: 19\n",
      "Total error streets: 142\n"
     ]
    }
   ],
   "source": [
    "osmfile = \"data/bergen.osm\"\n",
    "\n",
    "audit(osmfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Improving names\n",
    "\n",
    "mapping = { \" Gate\": \" gate\",\n",
    "            }\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    street_type = name[-5:]\n",
    "    \n",
    "    if street_type in mapping.keys():\n",
    "        name = re.sub(street_type,mapping[street_type],name)\n",
    "\n",
    "    return name\n",
    "\n",
    "def generate_new_names(street_types):\n",
    "    better_names = {}\n",
    "    for st_type, ways in street_types.items():\n",
    "\n",
    "        for old_name in ways:\n",
    "            \n",
    "            #if old_name ends in street number, remove street number\n",
    "            if re.search(' [0-9]*$',old_name):\n",
    "                better_name = re.sub(' [0-9]*$','',old_name)\n",
    "                \n",
    "            else:\n",
    "                better_name = update_name(old_name, mapping)\n",
    "            better_names[old_name] = better_name\n",
    "            \n",
    "    return better_names\n",
    "\n",
    "better_names = generate_new_names(street_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Laguneveien 1': 'Laguneveien',\n",
       " 'Smøråshøgda 9': 'Smøråshøgda',\n",
       " 'Thormøhlens Gate': 'Thormøhlens gate'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import json \n",
    "\n",
    "with codecs.open(\"test.json\", \"w\") as fo:\n",
    "    tmp_fo = fo.write(json.dumps(\"bradæ å æ\", ensure_ascii=False))\n",
    "    print(type(tmp_fo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5051'"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'NO-5051'[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before correcting the data I will make sure the postcodes in the OSM datasets all match the list of official Norway postcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erroneous postcode: NO-5059\n",
      "Erroneous postcode: NO-5059\n",
      "Erroneous postcode: NO-5035\n",
      "Erroneous postcode: NO-5059\n",
      "SUMMARY\n",
      "Count of evaluated post codes: 83755\n",
      "Count of discovered errors: 4\n",
      "New errors: 0\n",
      "--------------\n",
      "Good news! The 2 corrected postcodes exists in the official list of Norway postcodes.\n"
     ]
    }
   ],
   "source": [
    "OSMFILE = 'data/bergen.osm'\n",
    "\n",
    "def audit():\n",
    "    \n",
    "    #Creating array of official Norway postcodes\n",
    "    s = postcodes_per_municipality['postal_code'].values\n",
    "    count = 0\n",
    "    error_count = 0\n",
    "    new_errors = 0 \n",
    "    \n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag in [\"way\",\"node\"]:\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postcode(tag):\n",
    "                    count += 1\n",
    "                    #Checking if audited postcode exists in official postcode list\n",
    "                    if tag.attrib['v'] not in s:\n",
    "                        error_count += 1\n",
    "                        print(\"Erroneous postcode:\", tag.attrib['v'])\n",
    "\n",
    "                        if tag.attrib['v'] not in error_postcodes.keys():\n",
    "                            new_errors += 1\n",
    "                            error_postcodes[tag.attrib['v']] = 1\n",
    "                        \n",
    "    print(\"----SUMMARY---\")\n",
    "    print(\"Count of evaluated post codes:\",count)\n",
    "    print(\"Count of discovered errors:\",error_count)\n",
    "    print(\"New errors:\",new_errors)\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    #Checking whether the corrected postcodes exist in official list of Norway postcodes\n",
    "    errors = 0\n",
    "    for postcode in error_postcodes.keys():\n",
    "        \n",
    "        if postcode[-4:] not in s:\n",
    "            errors += 1\n",
    "            print(\"WARNING: {0} not in list of official postcodes!\".format(postcode))\n",
    "    if errors == 0:\n",
    "        print(\"Good news! The {0} corrected postcodes exists in the official list of Norway postcodes.\".\\\n",
    "        format(len(error_postcodes)))\n",
    "                    \n",
    "    \n",
    "audit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next I will write functions for making corrections based on the audit results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "multi_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*:(.)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "# el = shape_element(element)\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "                \n",
    "        node['type'] = element.tag\n",
    "\n",
    "        created = dict()\n",
    "        address = dict()\n",
    "        colon_dict = dict()\n",
    "        node_refs = list()\n",
    "        \n",
    "        for nod in element.iter():  \n",
    "            if element.tag == 'way' and nod.tag == 'nd':\n",
    "                node_refs.append(nod.attrib['ref'])\n",
    "                \n",
    "            for k,v in nod.attrib.items():\n",
    "            \n",
    "                if 'k' in nod.keys():\n",
    "                    node_key = nod.attrib['k']\n",
    "                    node_val = nod.attrib['v']\n",
    "                else:\n",
    "                    node_key = ''\n",
    "                    node_val = ''\n",
    "            \n",
    "#                 node_keys = nod.keys()\n",
    "#                 node_vals = nod.attrib\n",
    "\n",
    "                if problemchars.search(node_key):\n",
    "                    pass\n",
    "\n",
    "                elif re.match('addr:',node_key):\n",
    "                    k_list = node_key.rstrip(':').split(':')[1:]\n",
    "                    k_len =  len(k_list)\n",
    "         \n",
    "                    if k_len == 1:\n",
    "                        #Correcting incorrect postcodes for the export file\n",
    "                        if k_list[0] == 'postcode' and node_val in error_postcodes.keys():\n",
    "                            address['postcode'] = node_val[-4:]\n",
    "                            addr_pc = address['postcode']\n",
    "                            assert type(addr_pc) is IntType, \"postcode is not an integer: {}\".format(addr_pc)\n",
    "                    \n",
    "                        #Correcting incorrect street names for the export file\n",
    "                        if k_list[0] == 'street' and node_val in better_names.keys():\n",
    "                            address['street'] = better_names[node_val]\n",
    "                            \n",
    "                            #Adding missing housenumbers\n",
    "                            try:\n",
    "#                                 print(\"TRYING\")\n",
    "#                                 print(node_val,node_val[-1])\n",
    "\n",
    "                                address['housenumber'] = int(node_val[-1])\n",
    "#                                 print(\"SUCCEEDED\")\n",
    "#                                 print(address)\n",
    "#                                 print('---------------')\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                            \n",
    "                            print(\"Correcting address\")\n",
    "                            print(node_val,better_names[node_val])\n",
    "                            print(\"Address so far:\",address)\n",
    "                        #Processing other address attributes\n",
    "                        else:\n",
    "                            address[k_list[0]] = node_val\n",
    "                    elif k_len == 2 and k_list[0] == 'street':\n",
    "                        pass\n",
    "                    \n",
    "                    elif k_len > 1:\n",
    "                        print(('RECHECK ADDRESS, UNEXPECTED  VARIABLE COUNT: {0}, {1}').format(k_len,k_list))\n",
    "                        print(k,v)\n",
    "                        print('------------------')\n",
    "                        for text in element.iter():\n",
    "                            print(text.attrib.items())\n",
    "                \n",
    "    \n",
    "                elif lower_colon.search(node_key):\n",
    "                    colon_dict[node_key] = node_val\n",
    "                \n",
    "                                \n",
    "                elif k in ('k','v','ref'):\n",
    "                    pass\n",
    "                \n",
    "                elif k in CREATED:\n",
    "                    created[k] = v\n",
    "                    \n",
    "                elif k == 'lat':\n",
    "                    lat = float(v)\n",
    "                elif k == 'lon':\n",
    "                    lon = float(v)\n",
    "\n",
    "                else:    \n",
    "                   \n",
    "                    node[k] = v\n",
    "                    \n",
    "                    if k == \"ref\":\n",
    "                        print(k,v)\n",
    "                \n",
    "                \n",
    "            \n",
    "            if 'lat' in nod.attrib.keys():\n",
    "                node['pos'] = [lat,lon]\n",
    "\n",
    "        node['created'] = created\n",
    "        \n",
    "        if len(node_refs) != 0:\n",
    "            node['node_refs'] = node_refs\n",
    "\n",
    "        if len(address) != 0:\n",
    "                node['address'] = {}\n",
    "                for key in address.keys():\n",
    "                    node['address'][key] = address[key]\n",
    "\n",
    "        if len(colon_dict) > 0:\n",
    "\n",
    "            for k in colon_dict:\n",
    "                k_list = k.rstrip(':').split(':')\n",
    "                if len(k_list) ==  2:\n",
    "                    node[k_list[0]] = {k_list[1] : colon_dict[k]} \n",
    "            \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            \n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if count == 100:\n",
    "                print(\"above 100\")\n",
    "            elif count == 1000:\n",
    "                print(\"above 1000\")\n",
    "            elif count == 10000:\n",
    "                print(\"above 10000\")\n",
    "            elif count == 100000:\n",
    "                print(\"above 100000\")            \n",
    "            \n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    #Turning off ascii control to allow Norwegian letters æøå\n",
    "                    fo.write(json.dumps(el, indent=2, ensure_ascii=False)+\"\\n\")\n",
    "                else:\n",
    "                    #Turning off ascii control to allow Norwegian letters æøå\n",
    "                    fo.write(json.dumps(el,ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "#         addr_count = 0\n",
    "#         for node in data:\n",
    "#             if (addr_count < 20) and 'address' in node.keys():-=0\n",
    "#                 addr_count += 1\n",
    "#                 pprint(node['address'])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above 100\n",
      "above 1000\n",
      "above 10000\n"
     ]
    }
   ],
   "source": [
    "#process and test sample\n",
    "def process_sample(input):\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map(input, False)\n",
    "#     pprint(data)   \n",
    "    \n",
    "    correct_first_elem = {\n",
    "        \"id\": \"358065\", \n",
    "        \"type\": \"node\", \n",
    "        \"pos\": [60.5320227, 5.2557628], \n",
    "        \"created\": {\n",
    "            \"changeset\": \"6007582\", \n",
    "            \"user\": \"danerikk\", \n",
    "            \"version\": \"2\", \n",
    "            \"uid\": \"114230\", \n",
    "            \"timestamp\": \"2010-10-10T22:30:34Z\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "#     pprint(data[-10:-1])\n",
    "    \n",
    "    assert data[0] == correct_first_elem\n",
    "    assert data[-1][\"node_refs\"] == [ \"4504040186\", \"4504040035\", \"4504040031\"] \n",
    "    \n",
    "    for row in data:\n",
    "        if row['id'] == \"423945451\":\n",
    "            id_exists = 1\n",
    "            assert row[\"address\"] == {\n",
    "                                    \"street\": \"Conrad Mohrs veg\", \n",
    "                                    \"housenumber\": \"15\",\n",
    "                                    \"city\": \"Bergen\",\n",
    "                                    \"postcode\": \"5072\"\n",
    "                                      }\n",
    "            assert row[\"node_refs\"] == [ \"4234494122\", \"4234494121\",  \"4234494120\", \"4234494119\", \n",
    "                                        \"4234494117\", \"4234494116\", \"4234494114\", \"4234494118\", \"4234494122\"]\n",
    "    #testing ID in previous test exists\n",
    "    assert id_exists == 1\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    process_sample('data/sample.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next I'll create and run a function to generate the export file to be imported into MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above 100\n",
      "above 1000\n",
      "above 10000\n",
      "above 100000\n",
      "Correcting address\n",
      "Laguneveien 1 Laguneveien\n",
      "Address so far: {'city': 'Rådal', 'housenumber': 1, 'street': 'Laguneveien'}\n",
      "Correcting address\n",
      "Laguneveien 1 Laguneveien\n",
      "Address so far: {'city': 'Rådal', 'housenumber': 1, 'street': 'Laguneveien'}\n",
      "RECHECK ADDRESS, UNEXPECTED  VARIABLE COUNT: 2, ['housenumber', 'source']\n",
      "k addr:housenumber:source\n",
      "------------------\n",
      "dict_items([('changeset', '25834169'), ('timestamp', '2014-10-03T15:33:00Z'), ('id', '1832087088'), ('user', 'Gnonthgol_import'), ('version', '4'), ('uid', '829905'), ('lat', '60.4056807'), ('lon', '5.324289')])\n",
      "dict_items([('k', 'addr:city'), ('v', 'Bergen')])\n",
      "dict_items([('k', 'addr:street'), ('v', 'Sandviksveien')])\n",
      "dict_items([('k', 'addr:postcode'), ('v', '5036')])\n",
      "dict_items([('k', 'addr:housenumber'), ('v', '1')])\n",
      "dict_items([('k', 'addr:housenumber:source'), ('v', 'survey')])\n",
      "RECHECK ADDRESS, UNEXPECTED  VARIABLE COUNT: 2, ['housenumber', 'source']\n",
      "v survey\n",
      "------------------\n",
      "dict_items([('changeset', '25834169'), ('timestamp', '2014-10-03T15:33:00Z'), ('id', '1832087088'), ('user', 'Gnonthgol_import'), ('version', '4'), ('uid', '829905'), ('lat', '60.4056807'), ('lon', '5.324289')])\n",
      "dict_items([('k', 'addr:city'), ('v', 'Bergen')])\n",
      "dict_items([('k', 'addr:street'), ('v', 'Sandviksveien')])\n",
      "dict_items([('k', 'addr:postcode'), ('v', '5036')])\n",
      "dict_items([('k', 'addr:housenumber'), ('v', '1')])\n",
      "dict_items([('k', 'addr:housenumber:source'), ('v', 'survey')])\n",
      "Correcting address\n",
      "Thormøhlens Gate Thormøhlens gate\n",
      "Address so far: {'city': 'Bergen', 'housenumber': '23', 'street': 'Thormøhlens gate', 'postcode': '5006', 'floor': '0'}\n",
      "Correcting address\n",
      "Thormøhlens Gate Thormøhlens gate\n",
      "Address so far: {'city': 'Bergen', 'housenumber': '23', 'street': 'Thormøhlens gate', 'postcode': '5006', 'floor': '0'}\n",
      "Correcting address\n",
      "Laguneveien 1 Laguneveien\n",
      "Address so far: {'city': 'Rådal', 'housenumber': 1, 'street': 'Laguneveien'}\n",
      "Correcting address\n",
      "Laguneveien 1 Laguneveien\n",
      "Address so far: {'city': 'Rådal', 'housenumber': 1, 'street': 'Laguneveien'}\n",
      "Correcting address\n",
      "Smøråshøgda 9 Smøråshøgda\n",
      "Address so far: {'city': 'Rådal', 'housenumber': 9, 'street': 'Smøråshøgda'}\n",
      "Correcting address\n",
      "Smøråshøgda 9 Smøråshøgda\n",
      "Address so far: {'city': 'Rådal', 'housenumber': 9, 'street': 'Smøråshøgda'}\n",
      "Correcting address\n",
      "Thormøhlens Gate Thormøhlens gate\n",
      "Address so far: {'city': 'Bergen', 'street': 'Thormøhlens gate', 'floor': '0'}\n",
      "Correcting address\n",
      "Thormøhlens Gate Thormøhlens gate\n",
      "Address so far: {'city': 'Bergen', 'street': 'Thormøhlens gate', 'floor': '0'}\n",
      "{'city': 'Rådal', 'housenumber': 1, 'street': 'Laguneveien', 'postcode': '5235'}\n"
     ]
    }
   ],
   "source": [
    "#Process and test Bergen\n",
    "def process_bergen(input):\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map(input, False)\n",
    "#     pprint(data)   \n",
    "    \n",
    "    correct_first_elem = {\n",
    "        \"id\": \"358065\", \n",
    "        \"type\": \"node\", \n",
    "        \"pos\": [60.5320227, 5.2557628], \n",
    "        \"created\": {\n",
    "            \"changeset\": \"6007582\", \n",
    "            \"user\": \"danerikk\", \n",
    "            \"version\": \"2\", \n",
    "            \"uid\": \"114230\", \n",
    "            \"timestamp\": \"2010-10-10T22:30:34Z\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "#     pprint(data[-10:-1])\n",
    "    \n",
    "    assert data[0] == correct_first_elem\n",
    "    assert data[-1][\"node_refs\"] == [ \"4427629468\", \"3984096773\", \"4427629467\", \"3984096770\", \n",
    "                                     \"3984252780\", \"3984096767\", \"3984187870\", \"3984105670\", \n",
    "                                     \"3984096775\", \"3984252779\" ] \n",
    "    \n",
    "    for row in data:\n",
    "        if row['id'] == \"423945451\":\n",
    "            id_exists = 1\n",
    "            assert row[\"address\"] == {\n",
    "                                    \"street\": \"Conrad Mohrs veg\", \n",
    "                                    \"housenumber\": \"15\",\n",
    "                                    \"city\": \"Bergen\",\n",
    "                                    \"postcode\": \"5072\"\n",
    "                                      }\n",
    "            assert row[\"node_refs\"] == [ \"4234494122\", \"4234494121\",  \"4234494120\", \"4234494119\", \n",
    "                                        \"4234494117\", \"4234494116\", \"4234494114\", \"4234494118\", \"4234494122\" ]\n",
    "            \n",
    "        if row['id'] == \"1652908136\":\n",
    "            print(row['address'])\n",
    "            assert row[\"address\"][\"housenumber\"] == 1 \n",
    "            \n",
    "\n",
    "    #testing ID in previous test exists\n",
    "    assert id_exists == 1\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    process_bergen('data/bergen.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Based on the above I will not make any adjustments, as the source of one document's house number does not appear to be valuable enough to create an exception. The file is now ready for mongodb import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sources:\n",
    "\n",
    "For downloading map data: \n",
    "- https://mapzen.com/data/metro-extracts/ \n",
    "- https://mapzen.com/documentation/metro-extracts/file-format/ \n",
    "\n",
    "http://www.openstreetmap.org/relation/404159#map=10/60.3572/5.4163\n",
    "\n",
    "For QA of street names:  \n",
    "- http://labs.vegdata.no/nvdb-datakatalog/\n",
    "- https://www.vegvesen.no/nvdb/apidokumentasjon/\n",
    "- https://no.wikipedia.org/wiki/Liste_over_Bergens_gater\n",
    "- http://www.bring.no/radgivning/sende-noe/adressetjenester/postnummer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Steps taken:  \n",
    "1. Clean street names  \n",
    "2. Generate json file from sample file  \n",
    "3. While reviewing the output file I noticed that the Norwegian characters æøå was not encoded correctly. After debugging for a while I figured out that the error happened in the json module when running json.dumps(). Setting ensure_ascii = False solved this.\n",
    "\n",
    "Steps to go:\n",
    "1. bug discovered related to ref and node_refs. Fix this. Is set in the else statement. Has to do with double-loop, time to take care of."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
