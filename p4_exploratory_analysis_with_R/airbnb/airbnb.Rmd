Airbnb Listing Analysis by Gisle Tveit Gaasemyr
========================================================

> **Tip**: You will see quoted sections like this throughout the template to
help you construct your report. Make sure that you remove these notes before
you finish and submit your project!

> **Tip**: One of the requirements of this project is that your code follows
good formatting techniques, including limiting your lines to 80 characters or
less. If you're using RStudio, go into Preferences \> Code \> Display to set up
a margin line to help you keep track of this guideline!

```{r echo=FALSE, message=FALSE, packages}
# Load all of the packages that you end up using in your analysis in this code
# chunk.

# Notice that the parameter "echo" was set to FALSE for this code chunk. This
# prevents the code from displaying in the knitted HTML output. You should set
# echo=FALSE for all code chunks in your file, unless it makes sense for your
# report to show the code that generated a particular plot.

# The other parameters for "message" and "warning" should also be set to FALSE
# for other code chunks once you have verified that each plot comes out as you
# want it to. This will clean up the flow of your report.

library(ggplot2)
library(tidyr)
library(dplyr)
library(scales)
library(gridExtra)
library(ggmap)

```

```{r echo=FALSE, Load_the_Data}
# Load the Data
airbnb = read.csv('data/airbnb_union.csv')
```

> **Tip**: [{remove}] Before you create any plots, it is a good idea to provide 
a short introduction into the dataset that you are planning to explore. Replace this
quoted text with that general information![{/remove}]

The dataset I have chosen consists of airbnb listing data from San Francisco 
collected at 28 different dates between November 2013 and July 2017. I originally 
downloaded the datasets from 
http://tomslee.net/airbnb-data-collection-get-the-data as individual files for 
each date, which I then combined into a single file. For more details on this, 
see union_script.R [add to repo].

For details on the content of the columns, see 
http://tomslee.net/airbnb-data-collection-get-the-data.

# Univariate Plots Section

> **Tip**: In this section, you should perform some preliminary exploration of
your dataset. Run some summaries of the data and create univariate plots to
understand the structure of the individual variables in your dataset. Don't
forget to add a comment after each plot or closely-related group of plots!
There should be multiple code chunks and text sections; the first one below is
just to help you get started.

I'll start my analysis by taking a look at some records to get an initial feel 
of the dataset.

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}
#Getting an initital look at some rows
head(airbnb)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}
#Getting an initital look at some rowsggmap(myMap) +
tail(airbnb)
```

Next I'll get some information about the data types.

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}
str(airbnb)
```

```{r Univariate_Plots}
#Setting correct format for dates
airbnb$date_collected <- as.Date(airbnb$date_collected)
```

I now want to get some summary statistics for the different fields in the 
dataframe. 

```{r}
summary(airbnb)
```

I am already seeing some trends in the data. For example, based on the 1st 
quartile and max value for overall_satisfication, I suspect that very few 
listings have ratings below 4 of 5. Let's plot this to take a closer look.

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}


plot = ggplot(airbnb, aes(x = overall_satisfaction, fill = I('#099DD9') ) ) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0,5,1)) +
  geom_text(stat='count',aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5))

plot

```

The plot confirms my suspicion: 81.9% of the ratings are 4 or higher, with more 
than 50% of the ratings being 5. However, it is interesting to see that 16.8% of 
the rooms have a rating of 0. Let's take a closer look at some summary 
statistics for these records to see if there's a data quality issue.

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}
airbnb %>% 
  filter(overall_satisfaction==0) %>% 
  summary()
```
The first thing I notice is that there seem to be a large amount of records 
with 0 reviews. According to the dataset description the overall_satisfaction 
consists of " The average rating (out of five) that the listing has received from 
those visitors who left a review." We can therefore assume that records with 0 
reviews should have rating set to NA, not 0-5. Let's take a look at how many 
records have 0 reviews and an overall_satisfaction between 0 and 5.

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}

#Count of records with 0 reviews and an overall_satisfaction between 0 and 5
airbnb %>% 
  filter(reviews == 0 & !is.na(overall_satisfaction)) %>% 
  nrow()

```

About 8% of the records match this criteria. Let's plot the overall_satisfaction 
for these records.

```{r echo=FALSE, Univariate_Plots}
data = filter(airbnb, reviews == 0 & !is.na(overall_satisfaction))

plot = ggplot(data, aes(x = overall_satisfaction, fill = I('#099DD9') ) ) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0,5,1)) +
  geom_text(stat='count',aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5))

plot

```

It looks like all 0 reviews records with a value in overall_satisfaction has it 
set to 0. I'll run a filtered querry to make sure.

```{r}
airbnb %>% 
  filter(reviews == 0 & overall_satisfaction > 0)
```

3 out of 205k records is practically 0. I will now plot the overall_satisfaction 
column again excluding the 0 reviews records. I will also update the airbnb 
dataframe and change the overall_satisfaction score from 0 to NA for these 
records.

```{r include=FALSE, Univariate_Plots}
#For QA
pre_change <- airbnb %>% 
  group_by(overall_satisfaction) %>% 
  summarise(n = n())

#Changing the overall_satisfaction score of 0 reviews records to NA
airbnb$overall_satisfaction <- 
  if_else(airbnb$reviews == 0, NA_real_, airbnb$overall_satisfaction)

#For QA
post_change <- airbnb %>% 
  group_by(overall_satisfaction) %>% 
  summarise(n = n())

#QA
pre_change
post_change
pre_change - post_change

```


```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}

plot = ggplot(filter(airbnb, reviews != 0), aes(x = overall_satisfaction, fill = I('#099DD9') ) ) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0,5,1)) +
  geom_text(stat='count',aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5))

plot
```
When excluding the zero reviews records, the percentage of records with an 
overall ranking of 0 goes down to 7.5. That's still a fair amount, but it's much 
more believeable than before. Let's run a summary query on these records to see 
if we can spot any trends.

```{r echo=FALSE, message=FALSE, warning=FALSE, Univariate_Plots}
airbnb %>% 
  filter(overall_satisfaction==0, reviews != 0) %>% 
  summary()
```

What stands out to me is that a large portion of these records have only one 
review. Let's compare the amount of reviews of these records 
with the full dataset.

```{r}
filter(airbnb, reviews != 0) %>% 
  group_by(reviews) %>% 
  summarise(n = n())

20367 + 12907

9857			+
  8049			+
  6292			+
  5475			+
  4837	
```


```{r}

p1 = ggplot(filter(airbnb, overall_satisfaction == 0 & reviews != 0), aes(x = reviews, fill = I('#099DD9') ) ) +
  geom_bar() +
#  scale_x_continuous(breaks = seq(0,5,1)) +
  geom_text(stat='count',aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5))

p2 = ggplot(filter(airbnb, reviews != 0), aes(x = reviews, fill = I('#099DD9') ) ) +
  geom_histogram(binwidth = 5) +
#   stat_bin(binwidth= 5, geom="text", aes(label = ..count.., y = 0.98*(..count..)) , 
# vjust = -1) +
  geom_text(stat='bin', binwidth=aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5)) +
  xlim(0,50) 
  # geom_text(stat='count',aes(
  #   label=scales::percent(..count../sum(..count..)),vjust=-0.5))

p2

grid.arrange(p1,p2,nrow = 1)

?stat_bin

```
[]noe her, fiks plot.[]
{gisle}
Next let's take a look at the price distribution.

```{r}
plot = ggplot(airbnb, aes(x = price, fill = I('#099DD9') ) ) +
  geom_bar()# +
#  scale_x_continuous(breaks = seq(0,max(airbnb$price),1000))

plot
```

Looks like there's some extreme outliers for the price variable. Let's zoom in 
to get a better sense of price distribution

```{r}
plot = ggplot(airbnb, aes(x = price, fill = I('#099DD9') ) ) +
  geom_histogram(binwidth = 10) +
  xlim(0,1000)
#  scale_x_continuous(breaks = seq(0,max(airbnb$price),1000))

plot
```
[something something]{gisle}

Setting the max price to 1000 gives a clearer picture of the price distribution. 
The plot is heavily right-skewed, with most prices being below 250.

```{r}
quantile(airbnb$price, probs = seq(0,1,0.01)) %>% 
  grid.table()
```

I suspect size of the units heavily affect price. Therefore I will make a couple 
extra variables to look at the prices at the same room levels[].

```{r}
airbnb$price_per_bedroom = airbnb$price / airbnb$bedrooms

#Removing infinite values
is.na(airbnb$price_per_bedroom) <- do.call(cbind,lapply(airbnb$price_per_bedroom, is.infinite))

airbnb %>% 
  group_by(room_type) %>% 
  summarise(n = n(), avg_price = mean(price, na.rm = TRUE), 
            avg_bedroom_price = mean(price_per_bedroom, na.rm = TRUE))
```


```{r}
airbnb$room_type

airbnb %>% 
  group_by(room_type) %>% 
  summarise(n = n(), min_rooms = min(bedrooms, na.rm = TRUE), 
            max_rooms = max(bedrooms, na.rm = TRUE))

?summarise

max(airbnb$bedrooms, na.rm = TRUE)
```

```{r}
length((airbnb$date_collected))
min((airbnb$date_collected))
max((airbnb$date_collected))

?grid.table

```


```{r}
#minstay
plot = ggplot(airbnb, aes(x = minstay, fill = I('#099DD9') ) ) +
  geom_bar()

plot
```
```{r}
#zooming in on <100 days
plot = ggplot(subset(airbnb, minstay <=100), aes(x = minstay, fill = I('#099DD9') ) ) +
  geom_bar() + 
  scale_x_continuous(breaks = seq(0,100,10))

plot
```
```{r}
#zooming in on <10 days
plot = ggplot(subset(airbnb, minstay <=10), aes(x = minstay, fill = I('#099DD9') ) ) +
  geom_bar() + 
  scale_x_continuous(breaks = seq(0,10,1))

plot
```
The majority of listings have 1-3 days set as the minimum length of time for renting their unit. Almost no hosts asks for a longer
minimum stay than 7 days, although there is a small spike at 30 days, indicating that some units are 
listed as monthly rentals.

```{r}
#bedrooms
plot = ggplot(airbnb, aes(x = bedrooms, fill = I('#099DD9') ) ) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0,max(subset(airbnb,!is.na(bedrooms))$bedrooms),1)) +
    geom_text(stat='count',aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5))

plot

```

```{r}
ggplot(filter(airbnb, reviews != 0), aes(x = overall_satisfaction, fill = I('#099DD9') ) ) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0,5,1)) +
  geom_text(stat='count',aes(
    label=scales::percent(..count../sum(..count..)),vjust=-0.5))
```


```{r}
#accommodates
plot = ggplot(airbnb, aes(x = accommodates, fill = I('#099DD9') ) ) +
  geom_bar()
#  scale_x_continuous(breaks = seq(0,max(subset(airbnb,!is.na(bedrooms))$bedrooms),1))

plot
```
```{r}
#accommodates
plot = ggplot(airbnb, aes(x = neighborhood, fill = I('#099DD9') ) ) +
  geom_bar() + 
  coord_flip() 
#  scale_x_continuous(breaks = seq(0,max(subset(airbnb,!is.na(bedrooms))$bedrooms),1))

plot
```


```{r} 
#accommodates
plot = ggplot(airbnb, aes(x = accommodates, fill = I('#099DD9') ) ) +
  geom_bar()
#  scale_x_continuous(breaks = seq(0,max(subset(airbnb,!is.na(bedrooms))$bedrooms),1))

plot
```

(gisle)


```{r}
ggplot(filter(airbnb, price < quantile(airbnb$price,0.99)), aes(x = price)) +
  geom_jitter(alpha = 1, stat = 'count')


ggplot(airbnb, aes(x = price_bin)) +
  geom_histogram(stat = 'count')

?geom_point

quantile(airbnb$price,0.75)

```


```{r}

```


> **Tip**: Make sure that you leave a blank line between the start / end of
each code block and the end / start of your Markdown text so that it is
formatted nicely in the knitted text. Note as well that text on consecutive
lines is treated as a single space. Make sure you have a blank line between
your paragraphs so that they too are formatted for easy readability.

# Univariate Analysis

> **Tip**: Now that you've completed your univariate explorations, it's time to
reflect on and summarize what you've found. Use the questions below to help you
gather your observations and add your own if you have other thoughts!

### What is the structure of your dataset?
There are 205,532 listings in the dataset. The listings were collected at 28 
different dates. between November 2013 and October 2017.


### What is/are the main feature(s) of interest in your dataset?

From my initial analysis I consider price and date to be the main features of 
interest in the data set. 

### What other features in the dataset do you think will help support your \
### investigation into your feature(s) of interest?
Price variations across neighborhoods will be interesting to take a look at. I 
believe number of bedrooms and room type are other interesting parameters which 
will greatly affect the price.

### Did you create any new variables from existing variables in the dataset?
Yes, I created price per bedroom, as that seemed to be the best indicator of 
size. Without taking unit size into account it is very hard to get a true price 
picture.

### Of the features you investigated, were there any unusual distributions? \
It is a little surprising to me how large the portion of 1 bedroom apartments is. 
More than half of the units on the market fit into this category. There's a chance 
some of these records really inform about the number of rooms available, not 
the actual amount of rooms in the unit. It will be interesting to later take a look at 
the bedroom distribution across room type.

### Did you perform any operations on the data to tidy, adjust, or change the form \
### of the data? If so, why did you do this?
Yes. I initially downloaded 28 separate files which I merged to one file using 
the tidy function union. For full details about this process, see [].

In the file you are reading now I have changed the data type of the date_collected 
column from factor to date, for easier handling later.[rephrase] During my 
analysis I found a data error which I corrected: 15 900[check] records with 0 
reviews did not have overall_satisfaction set to NA, and >99.9% of these records 
had overall_satisfaction set to 0. I changed the overall_satisfaction of these 
records to NA.

# Bivariate Plots Section

> **Tip**: Based on what you saw in the univariate plots, what relationships
between variables might be interesting to look at in this section? Don't limit
yourself to relationships between a main output feature and one of the
supporting variables. Try to look at relationships between supporting variables
as well.

In this section, among other things I want to take a closer look at the relationship 
between price and neighborhood, and price and time.

Before I go any further, I want to make sure the neighborhood data is correct. 
Since the dataset contains latitude and longitude data, this is fairly easy to 
check using a map plot.

```{r fig.height=6, fig.width=6}
ggmap(myMap) +
geom_jitter(alpha = 0.01, aes(x=longitude, y=latitude), 
           data= airbnb) +
  facet_wrap(~neighborhood)

```

This is the result I was hoping for. The data points are nicely clustered within 
their respective neighborhoods. Based on local knowledge I can confirm that the 
names of the neighborhoods are correct.

```{r}
ggplot(airbnb, aes(x = neighborhood, y = price)) +
  geom_bar(stat = 'summary', fun.y = mean) +
  coord_flip()
```


```{r echo=FALSE, Bivariate_Plots}

ggplot(airbnb, aes(y = price)) +
  geom_bar(stat = 'summary', fun.y = mean, aes(x = reorder(neighborhood, price))) +
  coord_flip()

```
(gisle)
```{r}
airbnb %>% 
  group_by(neighborhood) %>% 
  summarise(n = n(), mean = mean(price), med = median(price), min = min(price), max = max(price)) %>% 
  arrange(desc(mean))
```


Presidio Heights and Presidio are clearly the most expensive neighborhoods, 
with an average price per night above $440. The most affordable neighborhods are 
Treasure Island, Crocker Amazon and Lakeshore. This makes sense, as they are all 
on the outskirts of the San Francisco city limits. Based on my local knowledge of 
the city there are no surprises in this figure.

```{r echo=FALSE, Bivariate_Plots}

ggplot(airbnb, aes(y = price)) +
  geom_bar(stat = 'summary', fun.y = mean, 
           aes(x = reorder(neighborhood, price), fill = I('gray50'))) +
  geom_bar(stat = 'summary', fun.y = mean, 
           aes(x = reorder(neighborhood, price),
               y = price_per_bedroom, fill = I('deepskyblue'))) +
  coord_flip() +
  scale_fill_manual(name = '', values =c('gray50'='gray50', 'deepskyblue'='deepskyblue'), 
                    labels = c('Price', 'Price per bedroom'))


```
(gisle)
When we compare the price to price per bedroom, Presidio Heights is no longer 
the most expensive neighborhoods. Now it seems like Downtown and the Financial 
District has the most expensive units. One thing to note is that this plot excludes any units 
with zero bedrooms  (roughly 13% of the records). Let's see if looking at median instead of 
mean changes things.

```{r}

#UNSURE what this is for, probably remove

ggplot(airbnb, aes(y = price)) +
  geom_bar(stat = 'summary', fun.y = median, 
           aes(x = reorder(neighborhood, price, FUN = median),
               y = price_per_bedroom, fill = I('deepskyblue'))) +
  coord_flip()
```


```{r echo=FALSE, Bivariate_Plots}

ggplot(airbnb, aes(y = price)) +
  geom_bar(stat = 'summary', fun.y = median, 
           aes(x = reorder(neighborhood, price, FUN = median), fill = I('gray50'))) +
  geom_bar(stat = 'summary', fun.y = median, 
           aes(x = reorder(neighborhood, price,  FUN = median),
               y = price_per_bedroom, fill = I('deepskyblue'))) +
  coord_flip() +
  scale_fill_manual(name = '', values =c('gray50'='gray50', 'deepskyblue'='deepskyblue'), 
                    labels = c('Price', 'Price per bedroom')) +
  labs(x = 'Neighborhood')

```

Looking at median instead of mean, the situation changes quite a bit. For absolute 
price, Presidio Heights and Presidio drop to 4th and 5th places, while Marina, 
Pacific Heights and Russian Hill now occupy the top 3. Presidio has the highest 
price per bedroom, with Marina and Chinatown having the 2nd and 3rd highest 
bedroom price.

Comparing the mean and median plots, it seems like some neighborhoods have some 
very expensive units, increasing the mean values. Especially Presidio and Presidio 
Heights seems to be affected by this. It doesn't seem to be same case the other 
way around, as all neighborhoods seem to have a higher mean than median price. 
Lets create another plot to confirm this.

```{r}
ggplot(airbnb, aes(y = price)) +
  geom_bar(stat = 'summary', fun.y = mean, 
           aes(x = reorder(neighborhood, price, FUN = mean), fill = I('gray50'))) +
  geom_bar(stat = 'summary', fun.y = median, 
           aes(x = reorder(neighborhood, price),
               fill = I('deepskyblue'))) +
  coord_flip() +
  scale_fill_manual(name = '', values =c('gray50'='gray50', 'deepskyblue'='deepskyblue'), 
                    labels = c('Median price', 'Mean price')) +
  labs(x = 'Neighborhood')
```

Indeed, no neightborhood has a higher median price than mean price. 

```{r}
#Creating table for neighborhood price

neighborhood_price <- airbnb %>%
  group_by(neighborhood) %>% 
  summarise(n = n(), mean = mean(price), median = median(price), 
            min = min(price), max = max(price)) %>% 
  arrange(desc(mean))

neighborhood_price

#neighborhood_price$mean - 
  
neighborhood_price$med


ggplot(neighborhood_price, aes(y = (median / mean), x = neighborhood)) +
  geom_bar(stat = 'identity') + 
  coord_flip()
  
?reorder
```

```{r}
ggplot(neighborhood_price, aes(y = (mean / median), x = neighborhood)) +
# ggplot(neighborhood_price, aes(y = mean, x = neighborhood)) +
  geom_point(aes(x = reorder(neighborhood, (mean / median), FUN = 'identity'))) +
  geom_bar(stat = 'identity', width = 0.1, aes(fill = I('gray50'))) + 
  ylab('Median price ratio of mean') +
  coord_flip() +
  theme_classic()

?geom_b

?theme_bw()
```

In this plot, which compares median and mean price per neighborhood), 
we see that the median price in Presidio Heights is almost 2.5 times greater 
than the mean price. It will be interesting to take a look at the effect of 
room type in the multivariate section later in this [term]. I also want to plot 
the prices per neighborhood in a scatter plot. [huh]

```{r}
#Price per bedroom vs price. Maybe remove

ggplot(airbnb, aes(x = price_per_bedroom, y = price)) +
  geom_point()

#Finding the outlier
subset(airbnb, price == max(airbnb$price))
```

```{r}
#Neighborhood counts over time
#Maybe move to next section

```

```{r}
#Price over time, mean

# ggplot(airbnb, aes(x = date_collected, y = price)) +
#     geom_line(stat = 'summary', fun.y = mean, aes(color = neighborhood))

ggplot(airbnb, aes(x = date_collected, y = price)) +
  geom_line(stat = 'summary', fun.y = mean) + 
  ylab('Mean price')

```

Except for one outlier date in 2015, the mean price have stayed fairly consistent 
roughly between 210 and 270,over the whole time period in the dataset (late 2013 
to mid-2017). This makes me curious about whether there was a special event in 
San Francisco at the time the data was collected which increased the prices 
dramatically, or if this is due to some outliers. Let's see if the median price 
follows the same trend.

```{r}
#Price over time, median

ggplot(airbnb, aes(x = date_collected, y = price)) +
  geom_line(stat = 'summary', fun.y = median) + 
  ylab('Median price')

```

At first glance the median price appears to be much more volatile than the mean 
price, but this is mainly due to the y axis being much more detailed[] in this 
last plot. Let's plot the statistics together to get a clearer picture.

```{r}
ggplot(airbnb, aes(x = date_collected, y = price)) +
  geom_line(stat = 'summary', fun.y = mean, aes(color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median,  aes(color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median'))

```

Here we see that median price in general follows the trend of the mean price. 
One interesting exception is the outlier date from the mean chart, which is not 
an outlier for median price. To me this indicates that the 2015 outlier date has 
some very high outlier prices. Let's investigate this further.

```{r}
#Number of records per date
# airbnb %>% 
#   group_by(date_collected) %>% 
#   summarise(count = n()) %>% 
#   ggplot(aes(x = date_collected, y = count)) +
#   geom_line()

ggplot(airbnb, aes(x=date_collected)) + 
  geom_line(stat= 'count')
```

There is not an unusal number of records for any dates in 2015, so this is probably 
not a relevant factor. Next I'll take a closer look at the data for the mean price 
outlier date.

```{r}
#Finding the outlier date

airbnb %>%
  group_by(date_collected) %>% 
  summarise(n = n(), mean = mean(price), median = median(price), 
            min = min(price), max = max(price)) %>% 
  arrange(desc(mean)) %>% 
  head()

```

2015-08-21 is the outlier date. 

```{r}
print("Running the summary() function on all the records.")
summary(airbnb)

print("Running the summary() function on the 2015-08-21 records.")
subset(airbnb, date_collected == '2015-08-21') %>% 
  summary()

```

Here I'm mostly interested in comparing quantiles for price and price_per_bedroom. 
These variables are not drastically different between the 2015-08-21 records and 
all records.

```{r}
#Boxplot of price per date

ggplot(airbnb, aes(x = date_collected, group = date_collected, y = price)) +
  geom_boxplot() + 
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months')

```
```{r}
ggplot(airbnb, aes(x = date_collected, group = date_collected, y = price)) +
  geom_boxplot() + 
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months') +
  ylim(0,10000) +
  ggtitle('Boxplot with price<=10000') +
  theme(title = element_text(size=9))

```
```{r}
ggplot(airbnb, aes(x = date_collected, group = date_collected, y = price)) +
  geom_boxplot() + 
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months') +
  ylim(0,1000) +
  ggtitle('Boxplot with price<=1000') +
  theme(title = element_text(size=9))

```

The boxplots indicates that the outliers above price 1000 are to blame, but 
doesn't give much more information than that. [rephrase] 

```{r}

subset(airbnb, price >= quantile(airbnb$price, 0.95)) %>% 
  ggplot(aes(x = date_collected)) +
  geom_bar() +
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months') +
  ggtitle('Top 5% prices in dataset') +
  theme(title = element_text(size=9))
```

```{r}
subset(airbnb, price >= quantile(airbnb$price, 0.98)) %>% 
  ggplot(aes(x = date_collected)) +
  geom_bar() +
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months') +
  ggtitle('Top 2% prices in dataset') +
  theme(title = element_text(size=9))
```

```{r}
subset(airbnb, price >= quantile(airbnb$price, 0.99)) %>% 
  ggplot(aes(x = date_collected)) +
  geom_bar() +
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months') +
  ggtitle('Top 1% prices in dataset') +
  theme(title = element_text(size=9))
```

Looking at the two bar charts above, we see that the August 2015 date does not 
have exceptionally many records with price higher than the top 5% prices in the 
whole dataset, but the August 2015 records do have a very large amount of the 
top 2% of prices in the dataset, and almost 3 times as many of the 1% top prices
as any other date in the dataset. Since this is showing absolute [] counts, and 
some of the later dates have more records than the August 2015 date, this becomes 
even more relevant [rephrase].


```{r}
#Percentile dataframe for all dates and the August 2015 date
df_percentiles = data.frame(all_records = quantile(airbnb$price, seq(0,1,0.01)),
           August_2015 = subset(
             airbnb, date_collected == '2015-08-21')$price %>% 
  quantile(seq(0,1,0.01)) )

#Creating row of numeric values for percentile for easier use with ggplot
df_percentiles$percentile <- seq(0,100,1)


```

```{r}
#Plotting percentiles
library(reshape2)
melted = melt(df_percentiles,id = c('percentile'))

ggplot(melted, aes(x = percentile, y = value)) +
  geom_line(aes(color = variable), stat = 'identity') + 
  scale_y_continuous(breaks = c(500,1000,5000,10000,20000,30000)) + 
  scale_x_continuous(breaks = seq(0,100,5))
```
Judging from the above plot, the August_2015 price followed the general price 
trend up to about the 90th percentile. Let's see if we can get some more details 
by applying a log transformation[].

```{r}
#Plotting percentiles, log scale
ggplot(melted, aes(x = percentile, y = value)) +
  geom_line(aes(color = variable), stat = 'identity') + 
  scale_y_log10(breaks = c(0,100,500,1000,5000,10000,20000,30000)) + #pretty_breaks(5)) + 
  scale_x_continuous(breaks = seq(0,100,5))

```

We get a little bit more details from the log transformation, but the trend 
stays the same:the August 2015 price follows the general trend until about the 
90th percentile, when the August 2015 price starts to become much higher than for 
the same percentiles in the whole dataset. I will plot this one last time to get 
a clearer picture of what is going on [rephrase].

```{r}
#Plotting percentiles, log scale
subset(melted, percentile >= 92) %>% 
  ggplot(aes(x = percentile, y = value)) +
  geom_line(aes(color = variable), stat = 'identity') + 
  scale_x_continuous(breaks = seq(90,100,1)) +
  scale_y_continuous(breaks = seq(0,30000,1000))

```

Compared to the August_2015, the 92nd to 99th percentiles for all_records are 
very flat. From the 95th percentile, the August_2015 values are many times larger 
than the values for all_records, only being surpassed at the max value at the 
100th percentile.

```{r}
ggplot(subset(airbnb, price < quantile(airbnb$price, 0.99)), aes(x = date_collected, y = price)) +
  geom_line(stat = 'summary', fun.y = mean, aes(color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median,  aes(color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median')) +
  ggtitle("price < 99th percentile", subtitle = "Top outliers removed.") + 
  scale_x_date(date_labels = "%b-%y", date_breaks = '6 months')
```

With the most extreme outliers removed, The August 2015 statistics are much less 
drastic[rephrase].



```{r}
ggplot(airbnb, aes(y = overall_satisfaction)) +
  geom_bar(stat = 'summary', fun.y = median,
           aes(x = reorder(neighborhood, overall_satisfaction, 
                           FUN = mean, na.rm = TRUE),
               fill = I('deepskyblue'))) +
    geom_bar(stat = 'summary', fun.y = mean, 
             aes(x = neighborhood, fill = I('gray50'))) +
  coord_flip() +
  scale_fill_manual(name = 'overall_satisfaction', 
                    values=c('gray50'='gray50', 'deepskyblue'='deepskyblue'),
                    labels = c('Median', 'Mean')) +
  labs(x = 'Neighborhood', y='')

```

```{r}
#Keep this one visible
subset(airbnb, neighborhood == 'Golden Gate Park')$overall_satisfaction %>% 
  mean(na.rm = TRUE)

subset(airbnb, neighborhood == 'Lakeshore')$overall_satisfaction %>% 
  mean(na.rm = TRUE)
```
(gisle)
All of the neighborhoods have a median overall_satisfaction score of either 4.5 
or 5. The mean score varies a little more, although all but two neighborhoods 
score 4 or better.

```{r}
ggplot(subset(airbnb, price < quantile(airbnb$price, 0.99)), 
       aes(y = price, x = overall_satisfaction)) +
  geom_jitter(alpha = 1/10) + 
  geom_smooth() +
  scale_y_continuous(breaks = c(0,50,seq(100, 1500,100))) +
  scale_x_continuous(breaks = seq(0,5,1)) +
  labs(caption = "Excluding top 1% prices")

```
(gisle)
```{r}
ggplot(subset(airbnb), 
       aes(x = overall_satisfaction, y = price)) +
  geom_line(stat = 'summary', fun.y = mean, aes(color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median,  aes(color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median'))
  
```

Based on the above we see quite some variation in [blahblah].

Keep in mind that only 1.5% of the records have an overall_satisfaction score of 
between 1 and 3.5, and 7.5% of the records have a score of 0. It is therefore 
most interesting to look at the price differences in the 4 to 5 
overall_satisfaction range, where there's a fairly clear trend: pricier units 
receive better scores.

```{r}
ggplot(subset(airbnb, bedrooms < quantile(airbnb$bedrooms, 0.995, na.rm = TRUE)), 
       aes(x = bedrooms, y = price)) +
  geom_line(stat = 'summary', fun.y = mean, aes(color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median,  aes(color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median')) +
  labs(caption = 'Excluding top 0.5% bedroom counts.')

```

```{r}
ggplot(subset(airbnb), 
       aes(x = accommodates, y = price)) +
  geom_line(stat = 'summary', fun.y = mean, aes(color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median,  aes(color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median')) 

```

```{r}
ggplot(subset(airbnb), 
       aes(x = accommodates, y = bedrooms)) +
  geom_line(stat = 'summary', fun.y = mean, aes(color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median,  aes(color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median')) 

```

```{r}
#Move to later
ggplot(airbnb, aes(x = date_collected, y = overall_satisfaction)) +
  geom_line(stat = 'summary', fun.y = mean) + 
  ylab('Median price')

#View(subset(airbnb, date_collected > as.Date('2016/12/31')))

#It's due to some NA values being set to 0 instead. Especially for 2017.

#Further investigations
ggplot(subset(airbnb, overall_satisfaction > 0), 
       aes(x = date_collected, y = overall_satisfaction)) +
  geom_line(stat = 'summary', fun.y = mean) + 
  ylab('Median price')

```


```{r}
#Making proportion table of room_type and date_collected
mutated = airbnb %>%
  group_by(date_collected, room_type) %>%
  summarise (n = n()) %>%
  mutate(Percentage = (n / sum(n)) * 100)

plot = ggplot(mutated, aes(x=date_collected, fill = room_type, y = Percentage))
  
plot + 
  geom_bar(stat = 'identity', position = 'jitter')

```
Due to the amount of dates, this is not very easy to read. Let's make a line 
chart instead.

```{r}

ggplot(mutated, aes(x=date_collected, color = room_type, y = Percentage)) +
  geom_line()
```

With the line chart we see a clearer picture. The proportion of Entire home/apt 
units have stayed fairly consistent throughout the time period, while private 
room units have increased and shared room units have decreased. I also notice 
that a few dates at the end of 2015 and in the beginning of 2016 lacks room_type 
information.

```{r}
airbnb %>% 
  filter(room_type == '') %>% 
  group_by(date_collected) %>% 
  summarise(n = n())
```



# Bivariate Analysis

> **Tip**: As before, summarize what you found in your bivariate explorations
here. Use the questions below to guide your discussion.

### Talk about some of the relationships you observed in this part of the \
### investigation. How did the feature(s) of interest vary with other features in \
### the dataset?

There is a fairly clear relationship between price and neighborhood. This makes 
sense, as some neighborhoods are more desirable than others. Based on local 
knowledge about San Francisco, it seems like the [blabla].

Except for some outlier price points in August 2015, the mean and median prices 
did not vary much over the 4 year period. The prices at the last date of data 
collections were actually lower than at most other dates.

When it comes to overall_satisfaction, there's a fairly clear trend for the 
higher scores: more expensive units receive a higher score.[rephrase?]

### Did you observe any interesting relationships between the other features \
(not the main feature(s) of interest)?

There appear to be a relationship between neighborhood and overall satisfaction. 
However, the correlation is not very strong, as all but 3 neighborhoods' mean 
score fall within 0.6 points of eachother.


### What was the strongest relationship you found?

The clearest relationship I found was price and number of bedrooms. 

[Expand]

# Multivariate Plots Section

> **Tip**: Now it's time to put everything together. Based on what you found in
the bivariate plots section, create a few multivariate plots to investigate
more complex interactions between variables. Make sure that the plots that you
create here are justified by the plots you explored in the previous section. If
you plan on creating any mathematical models, this is the section where you
will do that.

```{r echo=FALSE, Multivariate_Plots}
ggplot(data = airbnb, aes(x = price)) + 
  geom_histogram() + 
  xlim(0,200) +
  facet_wrap(~ room_type, nrow = 1)


#Adjusting for positive skew
ggplot(data = diamonds, aes(x = price, fill = cut)) + 
  geom_histogram() + 
  facet_wrap(~ color) +
  coord_trans(x = "log10") + 
  xlim(100,20000)

```

```{r}
mutated = filter(airbnb, room_type != '', 
                 price <= quantile(airbnb$price, 0.99)) %>%
  group_by(date_collected, room_type) %>%
  summarise (n = n(), mean_price = mean(price), median_price = median(price))

ggplot(mutated, aes(x=date_collected, color = room_type)) +
  geom_line(aes(y = mean_price), linetype = 'solid', show.legend = TRUE) +
  geom_line(aes(y = median_price), linetype = 'longdash', size = 0.5, show.legend = TRUE) +
  labs(y = 'Price', caption = 'Excluding top 1% prices.') +
  ggtitle('Prices per room type over time', 
          subtitle = "Solid lines show mean, dashed lines show median.") +
  theme(plot.caption = element_text(size = 8, hjust = 0), 
        plot.title = element_text(size = 12), 
        plot.subtitle = element_text(size = 9)) +
    scale_color_manual(name='Median', values = c('red','blue','forestgreen'))


```

The prices of entire home units have increased somewhat since the early days. 
Private rooms first have become a littl a little bit cheaper, while shared rooms, excluding one 
date in August 2015, has been fairly stable. [rephrase, more.]

```{r}
#Creating filter for plotting, excluding top 1% room counts.
filtered = filter(airbnb, bedrooms <= quantile(airbnb$bedrooms, 0.99, na.rm = TRUE))

#For annotation purposes, number of observations
# bedroom_counts = filtered %>% 
#   group_by(bedrooms) %>% 
#   summarise(n = n())
# 
# bedroom_counts$n_equals <- paste("n = ", bedroom_counts$n)

ggplot(data = filtered, aes(x = date_collected, y = price)) + 
  geom_line(stat='summary', fun.y = 'mean', aes(linetype = 'mean')) + 
    geom_line(stat='summary', fun.y = 'median', aes(linetype = 'median')) + 
    scale_linetype_manual(name="",values=c(mean="solid", median="dashed")) +
  ggtitle('Price by number of bedrooms 2013-2017') +
  facet_wrap(~ bedrooms) +
  theme(plot.title = element_text(size=11),
        legend.position = c(0.9, 0.1), legend.justification = c(1, 0))

```

Looking at the median values, it appears that most sizes [blahblah]



```{r}
ggplot(data = subset(airbnb, bedrooms <= 4), 
       aes(x = accommodates, y = price,  color = as.character(bedrooms))) +
  geom_smooth() +
#  scale_y_log10() +
  scale_color_brewer(type = 'div')

```


```{r}
ggplot(data = subset(airbnb, bedrooms <= 4), 
       aes(x = accommodates, y = price,  color = as.character(bedrooms))) +
  geom_jitter() +
  scale_y_log10() +
  scale_color_brewer(type = 'div')

```

[probably remove the above]

```{r}

filtered = subset(airbnb, price <= quantile(airbnb$price, 0.90))

ggplot(filtered, aes(x = as.character(date_collected), y = room_type))+
  geom_raster(aes(fill = price_per_bedroom))+
  labs(title ="Heat Map", x = "Outlet Identifier", y = "Item Type")+
#  scale_fill_continuous(name = "Item MRP") 
scale_fill_gradientn(colors = colorRampPalette(c("cadetblue1", "cadetblue4"))(100)) 

 ?scale_fill_gradientn(colors = colorRampPalette(c("cornsilk", "cornsilk3"))(100)) 
```
[remove the above]

```{r}
# install.packages("corrgram")
library(corrgram)

corrgram(airbnb, order=NULL, panel=panel.shade, text.panel=panel.txt,
           main="Correlogram")

```

[unclear if keep or remove]



[map experiment, expand or remove] (gisle)

```{r fig.height = 12, fig.width = 8}
install.packages("ggmap", type = "source")
library(ggmap)

myLocation <- "San Francisco"

myMap <- get_map(location = c(lon= -122.431297,lat = 37.773972), source = "google", 
                 maptype = 'terrain', crop = FALSE, zoom = 12)

sessionInfo()

# ?get_openstreetmap
# 
# ?ggmap(myMap)
# 
# ?get_map
# 
# qmplot(data = airbnb, x=longitude, y=latitude)

ggmap(myMap) +
geom_jitter(alpha = 0.01, aes(x=longitude, y=latitude), 
           data= filter(airbnb, !is.na(price_bin))) +
  facet_wrap(~price_bin)
  

ggmap(myMap) +
geom_point(alpha = 0.01, aes(x=longitude, y=latitude, color = price_bin), data=airbnb) +
  facet_wrap(~date_collected)


# map <- get_map(location = "texas", zoom = 6, source = "stamen", urlonly = TRUE)
# 
# map <- get_map(location=c(lon = -98.35, lat = 39.50), zoom = 8, source="google",maptype="roadmap",crop=FALSE)
```

Some dates appear to [use better color schemes].

```{r}
neighborhood_price_multi <- airbnb %>%
  group_by(neighborhood, room_type) %>% 
  summarise(n = n(), mean = mean(price), median = median(price), 
            min = min(price), max = max(price)) %>% 
  arrange(desc(mean))

ggplot(filter(neighborhood_price_multi, room_type != ''), aes(y = median, x = neighborhood) ) +
  geom_point(aes(x = reorder(neighborhood, median)) ) +
  geom_bar(stat = 'identity', width = 0.1, aes(fill = I('gray50'))) +
  ylab('Median price ratio of mean') +
  coord_flip() +
  theme_classic() +
  facet_wrap(~room_type)
```

We see here that room type seems to affect the median price more than [blah].


```{r fig.height = 8, fig.width = 7}

ggplot(airbnb, aes(x = date_collected, y = price_per_bedroom)) +
  geom_line(stat = 'summary', fun.y = median) +
  theme_light() +
  facet_wrap(~ neighborhood, ncol = 5)

```

```{r fig.height = 8, fig.width = 8}
ggplot(airbnb, aes(x = date_collected)) +
  geom_line(stat = 'summary', fun.y = median, 
            aes(y = price, color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median, 
            aes(y = price_per_bedroom, color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', 
                     values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median')) + 
  facet_wrap(~ neighborhood, ncol = 5)


```

Looking at this, Presidio stands out. While the median is fairly stable throughout the 
time period[term], the mean price varies drastically. Let's take a closer look at 
Presidio to figure out what is going on. 

```{r}
Presidio <-
  airbnb %>% 
  subset(neighborhood == 'Presidio') %>% 
  group_by(date_collected) %>% 
  summarise(n = n(), mean = mean(price), median = median(price), min = min(price),
            max = max(price), mean_bedrooms = mean(bedrooms) )

Presidio

```
 
 Looking at the summary statistics, there seem to be a clear problem with drawing any 
 conclusions from the Presidio data: the sample size per date is just too small, 
 with most dates having less than 10 records [term] [phrasing]. Let's take a look 
 at the sample sizes for all neighborhoods.
```{r}

airbnb %>% subset(neighborhood == 'Presidio') %>% 
  group_by(date_collected) %>% 
  summarise(n = n(), mean = mean(price), median = median(price), min = min(price),
            max = max(price), mean_bedrooms = mean(bedrooms) )

```

```{r}
neighborhood_count <-  
  airbnb %>% 
  group_by(neighborhood) %>% 
  summarise(n = n()) %>% 
  arrange(n)

neighborhood_count
```

Presidio is clearly the most troublesome neighborhood in this regard, having 
nearly 60% fewer records [term] than the second lowest neighborhood. However, 
some of the other neightborhoods might also have too few records to be [statistically 
viable]. Let's take a  closer look at the records with less than 1000 total records.


```{r}

filter_values <- filter(neighborhood_count, n <=1000)$neighborhood

ggplot(filter(airbnb, neighborhood %in% filter_values), aes(x = date_collected)) +
  geom_line(stat = 'count') +
  theme_light() +
  facet_wrap(~ neighborhood, ncol = 5)

```
 
 Too some extent all of these are troubling [expand].
 

```{r fig.height = 8, fig.width = 8}
ggplot(filter(airbnb, !(neighborhood %in% filter_values)), aes(x = date_collected)) +
  geom_line(stat = 'summary', fun.y = median, 
            aes(y = price, color = I('blue'))) +
  geom_line(stat = 'summary', fun.y = median, 
            aes(y = price_per_bedroom, color = I('forestgreen'))) +
 theme_light() +
  scale_color_manual(name = '', 
                     values =c('blue'='blue', 'forestgreen'='forestgreen'), 
                    labels = c('Mean', 'Median')) + 
  facet_wrap(~ neighborhood, ncol = 5)


```
Excluding the low-record neighborhoods shows a clearer relationship between mean 
and median for all neighborhoods. I also notice that except for the first date, 
which we know has much less records compared to the other dates, the median 
prices within neighborhoods stayed fairly stable throughout the time period. The 
same is true for mean, except for Presidio Heights, which had some large outliers 
on certain dates.[rephrase?]


```{r}

#Creating price bins
airbnb$price_bin <- percent_rank(airbnb$price) %>% 
  cut(breaks = seq(0,1,0.25), labels = seq(0.25,1,0.25))
```


```{r}
ggmap(myMap) +
    geom_jitter(size = 0.1, alpha = 0.01, aes(x=longitude, y=latitude), data=airbnb)

```

```{r fig.height = 6, fig.width = 6}

ggmap(myMap) +
geom_jitter(alpha = 0.01, size = 1, aes(x=longitude, y=latitude), 
           data= filter(airbnb, !is.na(price_bin))) +
  facet_wrap(~price_bin)

```

It looks to me like the most affordable units are widely distrbuted throughout 
all the neighborhoods, while the most expensive units can mostly be found in the 
most central parts of the city. [save for later:]I interpret this to mean that 
the neighborhoods (...).


```{r}
ggmap(myMap) +
geom_point(alpha = 0.01, aes(x=longitude, y=latitude, color = price_bin), data=airbnb) +
  facet_wrap(~date_collected)
```

```{r}
airbnb$price_bin_custom <- 
  airbnb$price %>% 
cut(breaks = c(0,100,200,300,400,500,1000,10000,max(airbnb$price)))

ggplot(airbnb, aes(x = price_bin_custom)) +
  geom_bar()
```

```{r fig.height = 8, fig.width = 6}

ggmap(myMap) +
geom_jitter(alpha = 0.01, size = 1, aes(x=longitude, y=latitude), 
           data= filter(airbnb, !is.na(price_bin_custom))) +
  facet_wrap(~price_bin_custom)

```

```{r}
# ggmap(myMap) +
# geom_jitter(alpha = 0.01, aes(x=longitude, y=latitude), 
#            data= filter(airbnb, !is.na(price_bin))) +
#   facet_wrap(~cut(percent_rank(price), breaks = seq(0,1,0.1)))
# 
# cut(percent_rank(head(airbnb$price,100)), breaks = seq(0,1,0.1))
```


```{r }

#fig.height = 12, fig.width = 12}

library(GGally)

paste(colnames(airbnb))

set.seed(1234)

#Excluding identifiers
airbnb_subset <- airbnb[, c(3:ncol(airbnb))]
airbnb_subset <- subset(airbnb_subset, select =-c(last_modified))

#Picking columns to compare
columns <- c('room_type', 'neighborhood', 'reviews', 'overall_satisfaction', 
             'accommodates', 'bedrooms', 'price', 'minstay', 'date_collected', 
             'price_per_bedroom')

airbnb_subset <- airbnb[, columns]

plot <- ggpairs(airbnb_subset[sample.int(nrow(airbnb), 10000), ],
         cardinality_threshold = nrow(distinct(airbnb,neighborhood)))

plot

?ggpairs

```

```{r}

columns <- c('room_type', 'neighborhood', 'reviews', 'overall_satisfaction', 
             'accommodates', 'bedrooms', 'price', 'minstay', 'date_collected', 
             'price_per_bedroom')

?cor(airbnb[,c('price','bedrooms','minstay','reviews')])
```

# Multivariate Analysis

### Talk about some of the relationships you observed in this part of the \
investigation. Were there features that strengthened each other in terms of \

looking at your feature(s) of interest?
Neighborhood and price have a clear correlation, even after including time as a 
variable. Both median and mean prices vary a fair amount from neighborhood to 
neighborhood, and prices within neighborhoods stayed fairly stable throughout the 
date range.

### Were there any interesting or surprising interactions between features?

I found it interesting how a relatively large dataset can still be too small for 
detailed analysis when you include multiple variables. The clearest example of this 
was how I had to exclude certain neighborhoods from my analysis due to having too 
few data points (less than 10) on certain dates.

### OPTIONAL: Did you create any models with your dataset? Discuss the \
strengths and limitations of your model.

------

# Final Plots and Summary

> **Tip**: You've done a lot of exploration and have built up an understanding
of the structure of and relationships between the variables in your dataset.
Here, you will select three plots from all of your previous exploration to
present here as a summary of some of your most interesting findings. Make sure
that you have refined your selected plots for good titling, axis labels (with
units), and good aesthetic choices (e.g. color, transparency). After each plot,
make sure you justify why you chose each plot by describing what it shows.

### Plot One
```{r echo=FALSE, Plot_One}
head(airbnb)
```

### Description One


```{r}
c('cd'=10,'cs'=100,'sd'=1000) %>% 
  Indometh

head(airbnb,20) %>% 
  mutate(rank = percent_rank(price)) %>% 
  cut(breaks = seq(1,10,1))
  
  
airbnb$price_bin <- percent_rank(airbnb$price) %>% 
  cut(breaks = seq(0,1,0.25), labels = seq(0.25,1,0.25))

  mutate(bin = if_else(rank > 0.5, 1, 2 ))

length(seq(1,10,1))

length(1:10)

?if_else

```


### Plot Two
```{r echo=FALSE, Plot_Two}

```

### Description Two


### Plot Three
```{r echo=FALSE, Plot_Three}

```

### Description Three

------

# Reflection

> **Tip**: Here's the final step! Reflect on the exploration you performed and
the insights you found. What were some of the struggles that you went through?
What went well? What was surprising? Make sure you include an insight into
future work that could be done with the dataset.

> **Tip**: Don't forget to remove this, and the other **Tip** sections before
saving your final work and knitting the final report!